# (PART\*) Inferenza statistica bayesiana {.unnumbered}


# Il problema inverso {#chapter-intro-bayes-inference}

```{r setup, include = FALSE}
source("_common.R")
```

<!-- La statistica descrittiva si occupa della descrizione, sintesi e presentazione delle informazioni contenute nei dati osservati. Essa spesso rappresenta la fase preliminare di uno studio e un ausilio per l'individuazione di possibili modelli da utilizzare nella successiva fase dell'analisi inferenziale. A differenza della statistica descrittiva, quella inferenziale assume che le osservazioni siano il risultato di un campionamento statistico e il suo obiettivo è ricavare informazioni circa l'intera popolazione a partire dall'osservazione di un suo sottoinsieme. -->

<!-- L'aleatorietà del campione è l'aspetto sostanziale che distingue la statistica inferenziale dalla statistica descrittiva. Nel caso più semplice, il campione statistico è trattato come un insieme di realizzazioni di una variabile casuale assunta a modello del fenomeno oggetto di indagine. La natura del campionamento statistico e la distribuzione di tale variabile casuale determinano il modello statistico. La statistica inferenziale consente di stimare, verificare ipotesi, o effettuare previsioni sul fenomeno in esame. -->

<!-- L'inferenza Bayesiana è un approccio all'inferenza statistica in cui le probabilità non sono interpretate come frequenze, proporzioni o concetti analoghi, ma piuttosto come il grado di fiducia che una singola persona attribuisce al verificarsi di un evento sulla base delle proprie conoscenze e delle informazioni di cui dispone.  -->


## Inferenza bayesiana come un problema inverso

L'inferenza bayesiana è formulata nei termini di un problema inverso che segue la regola di Bayes (si veda la Sezione \@ref(inf-stat-probl-inv)).^[Nell'approccio bayesiano non si fa riferimento ad un modello probabilistico $f(y \mid \theta)$ rappresentativo del fenomeno d'interesse noto a meno del valore assunto dal parametro (o dei parametri) che lo caratterizza. Si fa invece riferimento ad una distribuzione congiunta (di massa o di densità di probabilità) $f(y, \theta)$. Entrambi gli argomenti della funzione $y$ e $\theta$ hanno natura di variabili casuali, laddove la nostra incertezza relativa a $y$ è dovuta alla naturale variabilità del fenomeno indagato (_variabilità aleatoria_), mentre la nostra incertezza relativa a $\theta$ è dovuta alla mancata conoscenza del suo valore numerico (_variabilità epistemica_).] Per fissare la notazione, nel seguito $y$ rappresenterà le variabili osservate, ovvero i dati, e $\theta$ rappresenterà i parametri incogniti di un modello statistico. Sia $y$ che $\theta$ sono concepiti come delle variabili casuali. Con $x$ verranno invece denotate le quantità note, come i predittori nel modello di regressione.


### Funzioni di probabilità

L'inferenza bayesiana utilizza le seguenti distribuzioni di probabilità (o densità di probabilità): 

- la *distribuzione a priori* $p(\theta)$ --- la credenza iniziale riguardo alla credibilità di ciascun valore $\theta$;
- la *funzione di verosimiglianza* $p(y \mid \theta)$ --- descrive quanto sono compatibili i dati osservati $Y = y$ con i diversi valori possibili di $\theta$; quantifica la credibilità il ricercatore assegnerebbe ai dati osservati se conoscesse il "vero" valore del parametro di interesse $\theta$;
- la *verosimiglianza marginale* $p(y)$ --- quanto sono credibili i dati $y$ alla luce della nostra credenza a priori relativamente a $\theta$. In termini formali:
$$
p(y) = \int_\theta p(y, \theta) d\theta = \int_\theta p(y \mid \theta) p(\theta) d\theta.
$$
- la *distribuzione a posteriori* $p(\theta \mid y)$ --- la nuova credenza a posteriori relativamente alla credibilità di ciascun valore $\theta$ alla luce dei dati $Y = y$.


### La regola di Bayes

Nel contesto di un modello statistico, la formula di Bayes permette di giungere alla distribuzione a posteriori $p(\theta \mid y)$ per il parametro di interesse $\theta$, come indicato dalla seguente catena di equazioni:
\begin{align}
p(\theta \mid y)  &= \displaystyle \frac{p(\theta,y)}{p(y)}
 \ \ \ \ \ \mbox{ [definizione di probabilità condizionata]}
\\
&= \displaystyle \frac{p(y \mid \theta) \, p(\theta)}{p(y)}
 \ \ \ \ \ \mbox{ [legge della probabilità composta]}
\\
&=  \displaystyle \frac{p(y \mid\theta) \, p(\theta)}
                        {\int_{\Theta} p(y,\theta) \, d\theta}
 \ \ \ \ \ \mbox{ [legge della probabilità totale]}
\\
&= \displaystyle \frac{p(y \mid\theta) \, p(\theta)}
                        {\int_{\Theta} p(y \mid\theta) \, p(\theta) \, d\theta}
 \ \ \ \ \ \mbox{ [legge della probabilità composta]}
\\
& \propto \displaystyle p(y \mid\theta) \, p(\theta)
(\#eq:bayesmodel)
\end{align}

La regola di Bayes "inverte" la probabilità della distribuzione a posteriori $p(\theta \mid y)$, esprimendola nei termini della funzione di verosimiglianza $p(y \mid \theta)$ e della distribuzione a priori $p(\theta)$. L'ultimo passo è importante per la stima della distribuzione a posteriori mediante i metodi Monte Carlo a catena di Markov, in quanto per questi metodi richiedono soltanto che le funzioni di probabilità siano definite a meno di una costante di proporzionalità. In altri termini, per la maggior parte degli scopi dell'inferenza inversa, è sufficiente calcolare la densità a posteriori non normalizzata, ovvero è possibile ignorare il denominatore bayesiano $p(y)$. La distribuzione a posteriori non normalizzata, dunque, si riduce al prodotto della varosimiglianza e della distribuzione a priori.

Possiamo dire che la regola di Bayes viene usata per aggiornare le credenze a priori su $\theta$ (ovvero, la distribuzione a priori) in modo tale da produrre le nuove credenze a posteriori $p(\theta \mid y)$ che combinano le informazioni fornite dai dati $y$ con le credenze precedenti. La distribuzione a posteriori riflette dunque l'aggiornamento delle credenze del ricercatore alla luce dei dati.

La \@ref(eq:bayesmodel) rende evidente che, in ottica bayesiana, la quantità di interesse $\theta$ non è fissata come nell'impostazione frequentista, ma è una variabile casuale la cui distribuzione di probabilità è influenzata sia dalle informazioni a priori sia dai dati a disposizione. In altre parole, nell'approccio bayesiano non esiste un valore vero di $\theta$, ma vogliamo fornire invece un giudizio di probabilità. Prima delle osservazioni, sulla base delle nostre conoscenze assegniamo a $\theta$ una distribuzione a priori di probabilità. Dopo le osservazioni, correggiamo il nostro giudizio e assegniamo a $\theta$ una distribuzione a posteriori di probabilità. La distribuzione a posteriori $p(\theta \mid y)$ contiene tutta l'informazione riguardante il parametro $\theta$ e viene utilizzata per produrre indicatori sintetici, per la determinazione di stime puntuali o intervallari, e per la verifica d'ipotesi.


## Inferenza bayesiana

Un esempio di inferenza bayesiana è quello nel quale i dati sono rappresentati da una proporzione. Per questo tipo di dati possiamo adottare il seguente modello statistico 
\begin{equation}
y  \sim \mbox{Bin}(n, \theta),
(\#eq:binomialmodel)
\end{equation}
laddove $\theta$ è la probabiltà che una prova Bernoulliana assuma il valore 1 e $n$ corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane $y_i$ che costituiscono il campione $y$ siano tra loro indipendenti e che ciascuna abbia la stessa probabilità $\theta \in [0, 1]$ di essere un "successo" (valore 1). In altre parole, il modello generatore dei dati avrà una funzione di massa di probabilità 
$$
p(y \mid \theta)
\ = \
\mbox{Bin}(y \mid n, \theta).
$$

Nei capitoli precedenti è stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilità a ciascun possibile valore $y \in \{0, 1, \dots, n\}$ _assumendo noto il valore del parametro_ $\theta$. Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su $\theta$ alla luce dei dati campionari $y$. In altre parole, riteniamo di conoscere il modello probabilistico che ha generato i dati, ma di tale modello non conosciamo i parametri. Nel caso presente, il modello probabilistico è quello binomiale. Noi vogliamo ottenere informazioni sul valore di $\theta$ conoscendo il numero $y$ di successi osservati nel campione.


::: {.rmdnote}

La \@ref(eq:binomialmodel) è un _modello statistico_. Tale modello non spiega perché, in ciascuna realizzazione, $Y$ assuma un particolare valore. Questo modello deve piuttosto essere inteso come un costrutto matematico che ha lo scopo di riflettere alcune proprietà del processo corrispondente ad una sequenza di prove Bernoulliane. In questo senso, è simile al modello di Isaac Newton dei moti planetari che utilizza equazioni differenziali. Le equazioni non sono i pianeti, ma solo descrizioni di come si muovono i pianeti in risposta alle forze gravitazionali. Modelli come quello di Newton ci permettono di prevedere alcuni fenomeni, come il moto dei pianeti, ad esempio. Ma in generale i modelli sono solo delle approssimazioni del fenomeno che vogliono descrivere.  Anche il modello di Newton, che produce previsioni estremamente accurate di ciò che possiamo osservare a occhio nudo a proposito del moto dei corpi celesti, è solo un'approssimazione dei modelli del moto e dei fenomeni gravitazionali che, in seguito, sono stati introdotti da Albert Einstein. E anche tali modelli successivi sono, a loro volta, solo un caso speciale della più generale teoria della relatività. In altre parole, modelli sempre migliori vengono proposti, laddove ogni successivo modello è migliore di quello precedente in quanto ne migliora le capacità di previsione, è più generale, o è più elegante.

Una parte del lavoro della ricerca in tutte le scienze consiste nel verificare le assunzioni dei modelli e, se necessario, nel migliorare i modelli dei fenomeni considerati. Un modello viene giudicato in relazione al suo obiettivo. Se l'obiettivo del modello molto semplice che stiamo discutendo è quello di prevedere la proporzione di casi nei quali $y_i = 1$, $i = 1, \dots, n$, allora un modello con un solo parametro come quello che abbiamo introdotto sopra può essere sufficiente. Ma l'evento $y_i=1$ (supponiamo: superare l'esame di Psicometria, oppure risultare positivi al COVID-19) dipende da molti fattori e se vogliamo rendere conto di una tale complessità, un modello come quello che stiamo discutendo qui certamente non sarà sufficiente.

Per concludere, un modello è un costrutto matematico il cui scopo è quello di rappresentare un qualche aspetto della realtà. Il valore di un tale strumento dipende dalla sua capacità di ottenere lo scopo per cui è stato costruito.
:::


### Notazione

Per rappresentare in un modo conciso i modelli statistici viene usata una notazione particolare. Ad esempio, invece di scrivere
$$
p(\theta) = \text{Beta}(1, 1),
$$
scriviamo:
$$
\theta \sim \text{Beta}(1, 1).
$$
Il simbolo "$\sim$" viene spesso letto "è distribuito come". Possiamo anche pensare che significhi che $\theta$ costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, per l'esempio presente, la verosimiglianza può essere scritta come:
$$
y \sim \text{Bin}(n, \theta).
$$

### Il problema inverso

Nel modello statistico che stiamo esaminando, il termine $n$ viene trattato come una costante nota e $\theta$ come una *variabile casuale*. Il parametro $\theta$ del modello rappresenta la probabilità che ciascuna prova Bernoulliana sia un "successo". Dato che $\theta$ è incognito, ma abbiamo a disposione un campione di dati, l'inferenza su $\theta$ può essere svolta, mediante la regola di Bayes, costruendo la distribuzione a posteriori $p(\theta \mid y)$. Una volta ottenuta la distribuzione a posteriori possiamo riassumerla, ad esempio, riportando l'intervallo centrale al 95% della distribuzione di densità, ovvero
$$
\mbox{Pr}\left[ 0.025 \leq \theta \leq 0.975
                \ \Big| \
		Y = y
         \right].
$$

Se vogliamo sapere, per esempio, se la probabilità di $y_i=1$ sia maggiore di 0.5, possiamo calcolare la probabilità dell'evento
$$
\mbox{Pr}\left[\theta > \frac{1}{2}
                \ \Bigg| \
		Y = y
         \right].
$$


### Cos'è un parametro del modello?

Il parametro di un modello è un valore che influenza la credibilità dei dati. Ad esempio, il singolo parametro $\theta$ del modello binomiale determina la forma della funzione di verosimiglianza binomiale. Ricordiamo che, per il modello binomiale, la funzione di verosimiglianza è:
$$
p(y \mid \theta, n) = \text{Bin}(y, n, \theta) = \binom{n}{y}\theta^y(1-\theta)^{n-y}.
$$

<!-- Per comprendere il ruolo del parametro $\theta$, possiamo generare un grafico della verosimiglianza dei dati come funzione di $\theta$. Poniamo $y = 23$ e $n = 30$. La figura mostra, per ogni possibile valore di $\theta \in [0, 1]$ (sull'asse orizzontale), la verosimiglianza dei dati (sull'asse verticale). Dalla figura notiamo che la credibilità dei dati dipende dal valore del parametro $\theta$: i dati risultano più o meno verosimili a seconda del valore di $\theta$. -->

<!-- ```{r ch-03-02-LH-Binomial-Model, fig.cap= "Funzione di verosimiglianza per il modello binomiale con $y = 23$ e $n = 30$.", echo = FALSE} -->
<!-- y <- 23 -->
<!-- n <- 30 -->
<!-- tibble( -->
<!--   theta = seq(0, 1, length.out = 4001), -->
<!--   L = dbinom(x = y, size = n, prob = theta) -->
<!-- ) %>% -->
<!--   ggplot(aes(x = theta, y = L)) + -->
<!--   geom_line() + -->
<!--   labs( -->
<!--     x = latex2exp::TeX("Probabilità di $Y=1$, ovvero $\\theta$"), -->
<!--     y = latex2exp::TeX("Verosimiglianza, $ Bin(k=23, N=30, \\theta)$") -->
<!--   ) -->
<!-- ``` -->


### La distribuzione a priori sui parametri

Quando adottiamo un approccio bayesiano, i parametri non più delle costanti incognite ma delle variabili casuali governate da una propria legge di distribuzione delle probabilità (probabilità a priori). La distribuzione a priori sui valori dei parametri $p(\theta)$ è parte integrante del modello statistico. Ciò implica che due modelli bayesiani possono condividere la stessa funzione di verosimiglianza, ma tuttavia devono essere considerati come modelli diversi se specificano diverse distribuzioni a priori. Ciò significa che, quando diciamo "Modello binomiale", intendiamo in realtà un'intera classe di modelli, ovvero tutti i possibili modelli che hanno la stessa verosimiglianza ma diverse distribuzioni a priori su $\theta$.

Nell'analisi dei dati bayesiana, la distribuzione a priori $p(\theta)$ codifica le credenze del ricercatore a proposito dei valori dei parametri, prima di avere osservato i dati. Idealmente, le credenze a priori che supportano la specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti, o altre motivazioni giustificabili. 

- Quando una nuova osservazione (p. es., vedo un cigno bianco) corrisponde alle mie convinzioni precedenti (p. es., la maggior parte dei cigni sono bianchi) sto rafforzando le mie convinzioni precedenti: più nuove osservazioni (p. es., più cigni bianchi vedo), più forti diventano le mie credenze precedenti.
- Tuttavia, quando una nuova osservazione (p. es., vedo un cigno nero) non corrisponde alle mie convinzioni precedenti, ciò contribuisca a diminuire la certezza delle mie convinzioni precedenti: più nuove osservazioni non corrispondenti raccolgo (p. es., più cigni neri vedo ), più deboli diventano le mie convinzioni precedenti. Fondamentalmente, più forti sono le mie credenze precedenti, più osservazioni non corrispondenti (ad esempio, cigni neri) devo raccogliere per cambiarle.

Pertanto, da una prospettiva bayesiana, l'incertezza intorno ai parametri di un modello *dopo* aver visto i dati (ovvero le distribuzioni a posteriori) deve includere anche le credenze precedenti. Se questo modo di ragionare sembra molto intuitivo, non è una coincidenza: vi sono infatti diverse teorie psicologiche che prendono l'aggiornamento bayesiano come modello di funzionamento di diversi processi cognitivi.


<!-- Tuttavia, le credenze soggettive sono solo uno dei possibili modi per giustificare le distribuzioni a priori sui parametri. -->

<!-- Possiamo distinguere tre tipi principali di motivazioni per le distribuzioni a priori $p(\theta)$. -->

<!-- 1. Le *distribuzioni a priori soggettive* catturano le credenze del ricercatore nel senso sopra descritto. -->
<!-- 2. Le *distribuzioni a priori con finalità pratiche* sono distribuzioni a priori che vengono utilizzate pragmaticamente a causa di una loro utilità specifica, ad esempio, perché semplificano un calcolo matematico o una simulazione al computer, o perché aiutano nel ragionamento statistico, come ad esempio quando vengono formulate gli *skeptical priors* che hanno l'obiettivo di lavorare in senso contrario ad una particolare conclusione. -->

Oltre alla motivazione che giustifica una distribuzione a priori, possiamo distinguere tra diverse distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze a priori, il che conduce alle *distribuzioni a priori non informative*, ovvero quelle che assegnano lo stesso livello di credibilità a tutti i valori dei parametri. Le distribuzioni a priori informative, d'altra parte, possono essere *debolmente informative* o *fortemente informative*, a seconda della forza della credenza che esprimono. Il caso più estremo di credenza a priori è quello che riassume il punto di vista del ricercatore nei termini di un  *unico valore* del parametro, il che assegna tutta la probabilità (massa o densità) su di un singolo valore di un parametro. Poiché questa non è più una distribuzione di probabilità, sebbene ne soddisfi la definizione, in questo caso si parla di una *distribuzione a priori degenerata*.

La figura seguente mostra esempi di distribuzioni a priori non informative, debolmente o fortemente informative, così come una distribuzione a priori espressa nei termini di un valore puntuale per il modello Binomiale. Le distribuzione a priori illustrate di seguito  sono le seguenti:

- *non informativa* : $\theta_c \sim \text{Beta}(1,1)$;
- *debolmente informativa* : $\theta_c \sim \text{Beta}(5,2)$;
- *fortemente informativa* : $\theta_c \sim \text{Beta}(50,20)$;
- *valore puntuale* : $\theta_c \sim \text{Beta}(\alpha, \beta)$ con $\alpha, \beta \rightarrow \infty$ e $\frac{\alpha}{\beta} = \frac{5}{2}$.

```{r ch-03-02-models-types-of-priors, echo = F, fig.cap = "Esempi di distribuzioni a priori per il parametro $\\theta_c$ nel Modello Binomiale."}
tibble(
  theta = seq(0, 1, length.out = 401),
  `non informativa` = dbeta(theta, 1, 1),
  `debolmente informativa` = dbeta(theta, 5, 2),
  `informativa` = dbeta(theta, 50, 20),
  `puntuale` = dbeta(theta, 50000, 20000)
) %>%
  pivot_longer(
    cols = -1,
    names_to = "prior_type",
    values_to = "prior"
  ) %>%
  mutate(
    prior_type = factor(prior_type, levels = c('non informativa', 'debolmente informativa', 'informativa', 'puntuale'))
  ) %>%
  ggplot(aes(x = theta, y = prior)) +
  geom_line() +
  facet_wrap(~ prior_type, ncol = 2, scales = "free") +
  labs(
    x = latex2exp::TeX("Probabilità di successo $\\theta_c$"),
    y = latex2exp::TeX("Probabilità a priori $P(\\theta_c)$")
    # title = latex2exp::TeX("Distribuzione a priori per $\\theta$ (Modello Binomiale).")
  )
```


### Scelta della distribuzione a priori

La selezione delle distribuzioni a priori è stata spesso vista come una delle scelte più importanti che un ricercatore fa quando implementa un modello bayesiano in quanto può avere un impatto sostanziale sui risultati finali.  La soggettività delle distribuzioni a priori è evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. A questa critica, @vandeSchoot2021modelling rispondono dicendo che, al di là della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. In secondo luogo, @vandeSchoot2021modelling notano come le distribuzioni a priori svolgono due importanti ruoli statistici: quello della "regolarizzazione della stima", ovvero, il processo che porta ad indebolire l'influenza indebita di osservazioni estreme, e quello del miglioramento dell'efficienza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione a posteriori. L'effetto della distribuzione a priori sulla distribuzione a posteriori verrà discusso nel Capitolo \@ref(chapter-balance).


## Verosimiglianza marginale {#verosim-marginale}

Al denominatore della regola di Bayes abbiamo la verosimiglianza marginale $p(y)$. Tale denominatore è espresso nei termini di un integrale che, tranne in pochi casi particolari, non ha una soluzione analitica. 
<!-- Per questa ragione, l'inferenza bayesiana procede calcolando una approssimazione della distribuzione a posteriori mediante metodi numerici. -->


<!-- Obiettivo di questo Paragrafo è chiarire questo concetto in riferimento al caso più semplice, ovvero quello della distribuzione binomiale. -->

<!-- Sia $Y$ una variabile casuale con funzione di massa di probabilità $p(Y)$. Iniziamo la discussione con un semplice esempio in cui supponiamo che la funzione di massa di probabilità della $Y$ sia definita nei termini del parametro $\theta$ e che $\theta$ possa assumere solo i valori 0.1, 0.5, 0.9, ciascuno con eguale probabilità. In altre parole, la probabilità che $\theta$ sia 0.1, 0.5, o 0.9 è sempre 1/3.  -->

<!-- Ponendo $n = 30$ e $y = 23$, ad esempio, la funzione di verosimiglianza diventa -->

<!-- $$ -->
<!-- p(y = 23, n = 30 \mid \theta) = \binom{30}{23} \theta^{23} (1-\theta)^{7}. -->
<!-- $$ -->
<!-- La _verosimiglianza marginale_ $p(y = 23, n = 30)$ basata su $\theta$ si ottiene marginalizzando rispetto al parametro $\theta$: per ogni possibile valore del parametro $\theta$, calcoliamo il valore della verosimiglianza e lo moltiplichiamo per la probabilità di $\theta$; poi sommiamo tutti i prodotti ottenuti in questo modo. Matematicamente, ciò significa eseguire l'operazione descritta di seguito. -->

<!-- Nell'esempio abbiamo tre possibili valori $\theta$ che chiameremo $\theta_1 = 0.1$, $\theta_2 = 0.5$ e $\theta_3 = 0.9$. Ciascuno ha probabilità 1/3, quindi $p(\theta_1) = p(\theta_2) = p(\theta_3) = 1/3$. Date queste informazioni possiamo calcolare la verosimiglianza marginale come segue: -->


<!-- \begin{align} -->
<!-- p(y = 23, n = 30) &= \binom{30}{23} \theta_1^{23} (1-\theta_1)^{7} \cdot p(\theta_1) \notag\\ -->
<!-- &+ \binom{30}{23} \theta_2^{23} (1-\theta_2)^{7} \cdot p(\theta_2) \notag\\ -->
<!-- &+ \binom{30}{23} \theta_3^{23} (1-\theta_3)^{7} \cdot p(\theta_3) \notag, -->
<!-- \end{align} -->

<!-- \noindent -->
<!-- ovvero -->

<!-- \begin{align} -->
<!-- p(y = 23, n = 30) &= \binom{30}{23} 0.1^{23} (1-0.1)^{7} \cdot \frac{1}{3} \notag\\ -->
<!-- &+ \binom{30}{23} 0.5^{23} (1-0.5)^{7} \cdot \frac{1}{3} \notag\\ -->
<!-- &+ \binom{30}{23} 0.9^{23} (1-0.9)^{7} \cdot \frac{1}{3} \notag. -->
<!-- \end{align} -->

<!-- È dunque possibile considerare la verosimiglianza marginale come una sorta di media ponderata della verosimiglianza, nella quale i "pesi" dipendono dalla credibilità dei valori del parametro. -->

<!-- L'esempio che abbiamo presentato sopra è artificiale perché al parametro $\theta$ abbiamo attribuito solo tre possibili valori. In  realtà, $\theta$ può assumere tutti i possibili valori compresi nell'intervallo [0, 1] e dunque la somma che dobbiamo calcolare avrà infiniti addendi. Dal punto di vista matematico, una tale somma corrisponde all'integrale: -->

<!-- $$ -->
<!-- p(y = 23, n = 30) = \int_0^1 \binom{30}{23} \theta^{23} (1-\theta)^{7} d\theta. -->
<!-- $$ -->

<!-- \noindent -->
<!-- L'integrale precedente descrive esattamente le stesse operazioni che abbiamo discusso nell'esempio "artificiale" in cui $\theta$ poteva assumere solo tre valori, eccetto che ora dobbiamo eseguire la somma dei prodotti calcolati su tutti gli infiniti valori $\theta$. Questo integrale corrisponde alla "marginalizzazione" del parametro $\theta$. Non è tuttavia necessario eseguire una tale operazione di maginalizzazione in forma analitica in quanto il precedente integrale può essere calcolato con R: -->

<!-- ```{r} -->
<!-- BinLik <- function(theta) { -->
<!--   choose(30, 23) * theta^23 * (1 - theta)^7 -->
<!-- } -->
<!-- integrate(BinLik, lower = 0, upper = 1)$value -->
<!-- ``` -->


<!-- ### Soluzione analitica -->

<!-- Qui di seguito è riportata la derivazione analitica. Sia $\theta \sim \Beta(a, b)$ e sia $y = \{y_1, \dots, y_n\} \sim \Bin(\theta, n)$. Ponendo  -->

<!-- $$ -->
<!-- B(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}, -->
<!-- $$ -->

<!-- \noindent -->
<!-- la verosimiglianza marginale diventa -->

<!-- \begin{align} -->
<!-- p(y) &= \binom{n}{y} \int p(y \mid \theta) p(\theta) d\theta \notag\\ -->
<!-- &= \binom{n}{y}\int_0^1 \theta^{y} (1 - \theta)^{n- y} \frac{1}{B(a,b)} \theta^{a-1} (1-\theta)^{b-1} d \theta \notag\\ -->
<!-- &= \binom{n}{y}\frac{1}{B(a,b)} \int_0^1 \theta^{y + a - 1} (1-\theta)^{n- y + b-1} \notag\\ -->
<!-- &= \binom{n}{y}\frac{B(y + a, n- y + b)}{B(a,b)}, -->
<!-- \end{align} -->

<!-- \noindent -->
<!-- in quanto -->

<!-- \begin{align} -->
<!-- \int_0^1 \frac{1}{B(a,b)} \theta^{a-1} (1-\theta)^{b-1} d \theta &= 1\notag\\ -->
<!-- \frac{1}{B(a,b)} \int_0^1  \theta^{a-1} (1-\theta)^{b-1} d \theta &= 1\notag\\ -->
<!-- \int_0^1  \theta^{a-1} (1-\theta)^{b-1} d \theta &= B(a,b). \notag -->
<!-- \end{align} -->

<!-- \noindent -->
<!-- Continuiamo con l'esempio precedente. Per replicare il risultato trovato per via numerica con R, assumiamo una distribuzione a priori uniforme, ovvero $\Beta(1, 1)$. I valori del problema sono i seguenti: -->

<!-- ```{r} -->
<!-- a <- 1 -->
<!-- b <- 1 -->
<!-- y <- 23 -->
<!-- n <- 30 -->
<!-- ``` -->

<!-- \noindent -->
<!-- e dunque -->

<!-- ```{r} -->
<!-- alpha <- y + a -->
<!-- beta <- n - y + b -->
<!-- ``` -->

<!-- \noindent -->
<!-- Definiamo -->

<!-- ```{r} -->
<!-- B <- function(a, b) { -->
<!--   (gamma(a) * gamma(b)) / gamma(a + b) -->
<!-- } -->
<!-- ``` -->

<!-- \noindent -->
<!-- Il risultato cercato si ottiene con -->

<!-- ```{r} -->
<!-- choose(30, 23) * B(alpha, beta) / B(a, b) -->
<!-- ``` -->

<!-- In conclusione, nel caso di una verosimiglianza binomiale $y = \sim \Bin(\theta, n)$ e di una distribuzione a priori  $\theta \sim \Beta(a, b)$, la verosimiglianza marginale diventa -->

<!-- \begin{equation} -->
<!-- \binom{n}{y}\frac{B(y + a, n - y + b)}{B(a, b)}. -->
<!-- (\#eq:constant-norm-beta-binom) -->
<!-- \end{equation} -->


## La distribuzione a posteriori

Ci sono due metodi principali per calcolare la distribuzione a posteriori $p(\theta \mid y)$:

- una precisa derivazione matematica formulata nei termini della distribuzione a priori coniugata alla distribuzione a posteriori (si veda il Capitolo \@ref(chapter-distr-coniugate)); tale procedura però ha un'applicabilità molto limitata;
- un metodo approssimato, molto facile da utilizzare in pratica, che dipende da metodi Monte Carlo basati su Catena di Markov (MCMC).

Una volta calcolata la distribuzione a posteriori dobbiamo riassumerla in qualche modo. Questo problema verrà discusso nel Capitolo \@ref(chapter-sintesi-distr-post).


## Considerazioni conclusive {-}

In base all'approccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l'esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, a quello che è il vero valore del parametro. Questa distribuzione a priori può essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o può essere  del tutto arbitraria. L'inferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilità dei possibili valori del parametro alla luce dei dati osservati e delle credenze a priori. Questa nuova distribuzione di probabilità è chiamata "distribuzione a posteriori" e riassume l'incertezza dell'inferenza.

<!-- L'approccio bayesiano riassumere l'incertezza dell'inferenza fornendo un intervallo di valori sulla distribuzione di probabilità a posteriori che include il 95% della probabilità --- questo intervallo è chiamato "intervallo di credibilità del 95%". -->




