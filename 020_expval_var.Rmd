# Valore atteso e varianza {#exp-val-and-variance-rv}

```{r setup, include = FALSE}
source("_common.R")
```

Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.

## Valore atteso

Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo "valore tipico". La nozione di "valore tipico", tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:

- la _media_ (somma dei valori divisa per il numero dei valori),
- la _mediana_ (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),
- la _moda_ (il valore che ricorre più spesso).

Per esempio, la media di $\{3, 1, 4, 1, 5\}$ è $\frac{3+1+4+1+5}{5} = 2.8$, la mediana è $3$ e la moda è $1$. Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per "valore tipico" quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione.
<!-- Supponiamo di ripetere un esperimento casuale molte volte in modo tale che ciascun valore $Y$ si presenti con una frequenza approssimativamente uguale alla sua probabilità. Per esempio, possiamo lanciare una coppia di dadi e osservare i valori di $S$ = "somma dei punti" e di $P$ = "prodotto dei punti". Ci poniamo il problema di definire il "risultato tipico" di questo esperimento in modo tale che esso corrisponda al valore medio dei valori della variabile casuale, quando l'esperimento casuale viene ripetuto tante volte.  -->

::: {.definition}
Sia $Y$ è una variabile casuale discreta che assume i valori $y_1, \dots, y_n$ con distribuzione $p(y)$,
ossia
$$
P(Y = y_i) = p(y_i),
$$
per definizione il *valore atteso* di $Y$, $\E(Y)$, è  
\begin{equation}
\E(Y) = \sum_{i=1}^n y_i \cdot p(y_i).
(\#eq:expval-discr)
\end{equation}
:::

A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.

::: {.example}
Calcoliamo il valore atteso della variabile casuale $Y$ corrispondente al lancio di una moneta equilibrata (testa: _Y_ = 1; croce: _Y_ = 0). 
$$
\E(Y) = \sum_{i=1}^{2} y_i \cdot P(y_i) = 0 \cdot \frac{1}{5} + 1 \cdot \frac{1}{5} = 0.5.
$$
::: 

::: {.example}
Supponiamo ora che _Y_ sia il risultato del lancio di un dado equilibrato. Il valore atteso di _Y_ diventa:
$$
\E(Y) = \sum_{i=1}^{6} y_i \cdot P(y_i) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \dots + 6 \cdot \frac{1}{6} = \frac{21}{6} = 3.5.
$$
::: 


### Interpretazione

Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di _previsione_ (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l'estensione naturale della nozione di probabilità soggettiva.^[Per completezza -- che potrebbe anche essere evitata -- aggiungo qui l'interpretazione frequentista. I frequentisti pensano al valore atteso della variabile casuale $Y$ come alla media di un enorme numero di realizzazioni della $Y$. Se si potesse esaminare un numero infinito di realizzazioni $Y$, allora la media di tali infiniti valori sarebbe esattamente uguale al valore atteso. Allora perché abbiamo bisogno di introdurre un concetto diverso da quello di "media"? La risposta è che la media aritmetica è una somma divisa per $n$: $\bar{Y} = \frac{\sum_{i=1}^n y_i}{n}.$ Le variabili casuali possono generare un numero infinito di valori possibili. Dato che dividere per infinito non è possibile, è necessario procedere in un altro modo. Possiamo dire, in termini frequentisti, che il valore atteso di una variabile casuale è una _media ponderata_ in cui il valore assegnato a ciacun evento elementare dello spazio campionario viene "pesato" per la sua probabilità di verificarsi, nel caso di variabili casuali discrete, o per la sua densità di probabilità, nel caso di variabili casuali continue. Il termine valore atteso è però un po' fuorviante. Infatti, esso potrebbe non corrispondere a nessuno dei valori che possono essere generati dalla variabile casuale. Quindi il valore atteso non è "atteso" nel senso che ci aspettiamo di vederlo comparire spesso. Ci aspettiamo invece che sia simile alla media di qualsiasi campione sufficientemente grande di realizzazioni della variabile casuale: $\E(Y) = \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i = 1}^n y_i.$.]

### Proprietà del valore atteso

La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:

\begin{equation}
\E(X + Y) = \E(X) + \E(Y).
(\#eq:prop-expval-linearity)
\end{equation}

\noindent
La \@ref(eq:prop-expval-linearity) sembra ragionevole quando $X$ e $Y$ sono indipendenti, ma è anche vera quando $X$ e $Y$ sono associati. Abbiamo anche che

\begin{equation}
\E(cY) = c \E(Y).
(\#eq:prop-expval-const)
\end{equation}

\noindent
La \@ref(eq:prop-expval-const) ci dice che possiamo estrarre una costante dall'operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali $X$ e $Y$ sono indipendenti, abbiamo che 

\begin{equation}
\E(X Y) = \E(X) \E(Y). 
(\#eq:expval-prod-ind-rv)
\end{equation}


:::{.exercise}
Si considerino le seguenti variabili casuali: $Y$, ovvero il numero che si ottiene dal lancio di un dado equilibrato, e $Y$, il numero di teste prodotto dal lancio di una moneta equilibrata. 
Poniamoci il problema di trovare il valore atteso di $X+Y$.

Per risolvere il problema iniziamo a costruire lo spazio campionario dell'esperimento casuale consistente nel lancio di un dado e di una moneta.

   $x/              y$     1        2        3        4        5        6
  --------------------- -------- -------- -------- -------- -------- --------
              0         (0, 1)   (0, 2)   (0, 3)   (0, 4)   (0, 5)   (0, 6)
              1         (1, 1)   (1, 2)   (1, 3)   (1, 4)   (1, 5)   (1, 6)

\noindent
ovvero

   $x/              y$     1        2        3        4        5        6
  --------------------- -------- -------- -------- -------- -------- --------
              0             1       2        3        4        5        6
              1             2       3        4        5        6        7

\noindent
Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero $Pr(\omega) = \frac{1}{12}$. Il valore atteso di $X+Y$ è dunque uguale a:

$$
\E(X+Y) = 1 \cdot \frac{1}{12} + 2 \cdot \frac{1}{12} + \dots + 7 \cdot \frac{1}{12} = 4.0.
$$
Lo stesso risultato si ottiene nel modo seguente:

$$
\E(X+Y) = \E(X) + E(Y) = 3.5 + 0.5 = 4.0.
$$
:::


:::{.exercise}
Si considerino le variabili casuali $X$ e $Y$ definite nel caso del lancio di tre monete equilibrate, dove $X$ conta il numero delle teste nei tre lanci e $Y$ conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali $X$ e $Y$. 

La distribuzione di probabilità congiunta $P(X, Y)$ è fornita nella tabella seguente. 

   $x/              y$    0     1    $p(Y)$
  --------------------- ----- ----- --------
            0            1/8    0     1/8
            1            2/8   1/8    3/8
            2            1/8   2/8    3/8
            3             0    1/8    1/8
         $p(y)$          4/8   4/8    1.0

\noindent
Il calcolo del valore atteso di $XY$ si riduce a
$$
\E(XY) = 1 \cdot \frac{1}{8} + 2 \cdot \frac{2}{8} + 3 \cdot \frac{1}{8} = 1.0.
$$
Si noti che le variabili casuali $Y$ e $Y$ non sono indipendenti. Dunque non possiamo usare la proprietà \@ref(thm:prodindrv). Infatti, il valore atteso di $X$ è
$$
\E(X) = 1 \cdot \frac{3}{8} + 2 \cdot \frac{3}{8} + 3 \cdot \frac{1}{8} = 1.5
$$
e il valore atteso di $Y$ è
$$
\E(Y) = 0 \cdot \frac{4}{8} + 1 \cdot \frac{4}{8} = 0.5.
$$
Dunque
$$
1.5 \cdot 0.5 \neq 1.0.
$$
:::


### Variabili casuali continue

Nel caso di una variabile casuale continua $Y$ il valore atteso diventa:

\begin{equation}
\E(Y) = \int_{-\infty}^{+\infty} y p(y) dy
(\#eq:def-ev-rv-cont)
\end{equation}

Anche in questo caso il valore atteso è una media ponderata della $y$, nella quale ciascun possibile valore $y$ è ponderato per il corrispondente valore della densità $p(y)$. Possiamo leggere l'integrale pensando che $y$ rappresenti l'ampiezza delle barre infinitamente strette di un istogramma, con la densità $p(y)$ che corrisponde all'altezza di tali barre e la notazione $\int_{-\infty}^{\infty}$ che corrisponde ad una somma.

\bigskip
  
Un'altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della $Y$ individua il valore $y$ più plausibile, ovvero il valore $y$ che massimizza la funzione di densità $p(y)$:

\begin{equation}
\Mo(Y) = \argmax_y p(y).
(\#eq:def-mode)
\end{equation}


## Varianza 

La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la _varianza_.

::: {.definition}
Se $Y$ è una variabile casuale discreta con distribuzione $p(y)$, per definizione la varianza di $Y$, $\Var(Y)$, è  
\begin{equation}
\Var(Y) = \E\Big[\big(Y - \E(Y)\big)^2\Big].
(\#eq:def-var-rv)
\end{equation}
:::

A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.^[Data una variabile casuale $Y$ con valore atteso $\E(Y)$, le "distanze" tra i valori di $Y$ e il valore atteso $\E(Y)$ definiscono la variabile casuale $Y - \E(Y)$ chiamata _scarto_, oppure _deviazione_ oppure _variabile casuale centrata_. La variabile $Y - \E(Y)$ equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell'origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto $Y - \E(Y)$ vale zero, dunque la media di tale variabile non può essere usata per quantificare la "dispersione" dei valori di $Y$ relativamente al suo valore medio. Occorre rendere sempre positivi i valori di $Y - \E(Y)$ e tale risultato viene ottenuto considerando la variabile casuale $\left(Y - \E(Y)\right)^2$.] Se denotiamo $\E(Y) = \mu$, la varianza $\Var(Y)$ diventa il valore atteso di $(Y - \mu)^2$.  

:::{.example #somma-due-dadi}
Posta $S$ uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, poniamoci il problema di calcolare la varianza di $S$.

La variabile casuale $S$ ha la seguente distribuzione di probabilità:

   $s$            2                   3             4               5                   6               7                8                9                10             11              12 
-------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
 $P(S = s)$     $\frac{1}{36}$   $\frac{2}{36}$   $\frac{3}{36}$   $\frac{4}{36}$   $\frac{5}{36}$   $\frac{6}{36}$   $\frac{5}{36}$   $\frac{4}{36}$   $\frac{3}{36}$   $\frac{2}{36}$   $\frac{1}{36}$

\noindent
Essendo $\E(S) = 7$, la varianza diventa

\begin{align}
\Var(S) &= \sum \left(S- \mathbb{E}(S)\right)^2 \cdot P(S) \notag\\
&= (2 - 7)^2 \cdot 0.0278 + (3-7)^2 \cdot 0.0556 + \dots + (12 - 7)^2 \cdot 0.0278 \notag\\
&= 5.8333.\notag
\end{align}
:::

### Formula alternativa per la varianza

C'è un modo più semplice per calcolare la varianza:

\begin{align}
\E\Big[\big(X - \E(Y)\big)^2\Big] &= \E\big(X^2 - 2X\E(Y) + \E(Y)^2\big)\notag\\
&= \E(Y^2) - 2\E(Y)\E(Y) + \E(Y)^2,\notag
\end{align}
dato che $\E(Y)$ è una costante; pertanto

\begin{equation}
\Var(Y) = \E(Y^2) - \big(\E(Y) \big)^2.
(\#eq:def-alt-var-rv)
\end{equation}
A parole: la varianza è la media dei quadrati meno il quadrato della media.

::: {.example}
Consideriamo la variabile casuale $Y$ che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8.
Il valore atteso di $Y$ è
$$
\E(Y) = 0 \cdot 0.2 + 1 \cdot 0.8 = 0.8.
$$
Usando la formula tradizionale della varianza otteniamo:
$$
\Var(Y) = (0 - 0.8)^2 \cdot 0.2 + (1 - 0.8)^2 \cdot 0.8 = 0.16.
$$
Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di $Y^2$ è
$$
\E(Y^2) = 0^2 \cdot 0.2 + 1^2 * 0.8 = 0.8.
$$
e la varianza diventa
$$
\Var(Y) = \E(Y^2) - \big(\E(Y) \big)^2 = 0.8 - 0.8^2 = 0.16.
$$
::: 

### Variabili casuali continue

Nel caso di una variabile casuale continua $Y$, la varianza diventa:

\begin{equation}
\Var(Y) = \int_{-\infty}^{+\infty} [y - \E(Y)]^2 p(y) dy
(\#eq:def-var-rv-cont)
\end{equation}

Come nel caso discreto, la varianza di una v.c. continua $y$ misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori $y$ dalla loro media.

## Deviazione standard

Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell'unità di misura della scala originaria si prende la radice quadrata.  Il valore risultante viene chiamato _deviazione standard_ e solitamente è denotato dalla lettera greca $\sigma$.

::: {.definition}
Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza: 
\begin{equation}
\sigma_Y = \sqrt{\Var(Y)}.
(\#eq:def-sd)
\end{equation}
::: 

Interpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori $y$ dalla loro media.

:::{.example}
Per i dadi equilibrati dell'esercizio \@ref(exm:somma-due-dadi), la deviazione standard della variabile casuale $S$ è uguale a $\sqrt{5.8333} =  2.4152$. 
:::

## Standardizzazione

:::{.definition}
Data una variabile casuale $Y$, si dice variabile standardizzata di $Y$ l'espressione

\begin{equation}
Z = \frac{Y - \E(Y)}{\sigma_Y}.
(\#eq:standardization)
\end{equation}
:::

Solitamente, una variabile standardizzata viene denotata con la lettera $Z$.

## Momenti di variabili casuali

:::{.definition}
Si chiama *momento* di ordine $q$ di una v.c. $X$, dotata di densità $p(x)$, la
quantità
\begin{equation}
\E(X^q) = \int_{-\infty}^{+\infty} x^q p(x) \; dx.
\end{equation}
Se $X$ è una v.c. discreta, i suoi momenti valgono:
\begin{equation}
\E(X^q) = \sum_i x_i^q p(x_i).
\end{equation}
:::

I momenti sono importanti parametri indicatori di certe proprietà di $X$. I più
noti sono senza dubbio quelli per $q = 1$ e $q = 2$. Il momento del primo ordine corrisponde al valore atteso di $X$. Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di $X$, operando una traslazione $x_0 = x − \E(X)$ che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.

## Funzione di ripartizione

Il concetto di funzione di ripartizione è molto importante nella teoria della probabilità, sia nel caso discreto, sia in quello continuo. L'insieme $\{\omega: Y \leq y\}$ è un evento in $\Omega$ e si può scrivere $(Y \leq y)$. A tale evento è possibile assegnare una probabilità $P(Y \leq y)$ che, al variare di $y \in \mathbb{R}$, definisce la funzione di ripartizione della variabile casuale $Y$.

:::{.definition}
Si chiama *funzione di ripartizione* o *funzione di distribuzione* della variabile casuale $X$ la funzione $F(X)$ definita da
\begin{equation}
F(X) \triangleq P(X \le x), \qquad x \in \mathbb{R}.
(\#eq:funrip)
\end{equation}
:::

Detto a parole: la funzione di distribuzione cumulata, o funzione di ripartizione di $X$, misura la probabilità che $X$ assuma valori minori o uguali al valore $x$.

La funzione di ripartizione è sempre non negativa, monotona non decrescente tra $0$ e $1$, tale che:
$$
\lim_{x \to -\infty} F_x(X) = F_X(-\infty) = 0, \quad \lim_{x \to +\infty} F_X(X) = F_X(+\infty) = 1.
$$

:::{.example}
Consideriamo l'esperimento casuale corrispondente al lancio di due monete. Sia $X$ il numero di volte in cui esce testa. La distribuzione di probabilità di $X$ è:
$$
P(X) = 
\begin{cases}
    0, & 0.25,\\
    1, & 0.50,\\
    2, & 0.25.
\end{cases}
$$
La funzione di ripartizione di $X$ è:
$$
    F(X) = 
\begin{cases}
    0,   & \text{se } x < 0,\\
    1/4, & \text{se } 0 \leq x < 1,\\
    3/4, & \text{se } 1 \leq x < 2,\\
     1,  & \text{se } 2 \leq x.
\end{cases}
$$
Il valore della funzione di ripartizione in corrispondenza di $x = 1.5$, ad esempio, è:
$$
F(1.5) = P(X \leq 1.5) = P(X=0) + P(X=1) = \frac{1}{4} + \frac{2}{4} = \frac{3}{4}.
$$
:::

