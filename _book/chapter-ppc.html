<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Data Science per psicologi</title>
  <meta name="description" content="Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science per psicologi" />
  
  <meta name="twitter:description" content="Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2021-09-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="046_ppc.html"><a href="#chapter-ppc"><i class="fa fa-check"></i><b>1</b> Distribuzione predittiva a posteriori</a>
<ul>
<li class="chapter" data-level="1.1" data-path="046_ppc.html"><a href="#un-esempio-concreto"><i class="fa fa-check"></i><b>1.1</b> Un esempio concreto</a></li>
<li class="chapter" data-level="1.2" data-path="046_ppc.html"><a href="#metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori"><i class="fa fa-check"></i><b>1.2</b> Metodi MCMC per la distribuzione predittiva a posteriori</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="046_ppc.html"><a href="#posterior-predictive-checks"><i class="fa fa-check"></i><b>1.2.1</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="1.2.2" data-path="046_ppc.html"><a href="#ppc-per-il-modello-di-poisson"><i class="fa fa-check"></i><b>1.2.2</b> PPC per il modello di Poisson</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#considerazioni-conclusive"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Data Science per psicologi</h1>
<p class="author"><em>Corrado Caudek</em></p>
<p class="date"><em>2021-09-13</em></p>
</div>
<div id="chapter-ppc" class="section level1" number="1">
<h1><span class="header-section-number">Capitolo 1</span> Distribuzione predittiva a posteriori</h1>
<p>Oltre alla stima a posteriori degli indici sintetici del parametro e alla verifica delle ipotesi, un altro compito comune in un’analisi bayesiana è la predizione di nuovi dati futuri.</p>
<div class="definition">
<p><span id="def:unlabeled-div-1" class="definition"><strong>Definizione 1.1  </strong></span>Si chiama <em>distribuzione predittiva a posteriori</em> (<em>posterior predictive distribution</em>, PPD), la distribuzione di future osservazioni di dati, ovvero la distribuzione sui possibili dati previsti futuri <span class="math inline">\(\tilde{y}\)</span> data la distribuzione a posteriori per <span class="math inline">\(\theta\)</span> che è stata ottenuta. La distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> è
<span class="math display" id="eq:dist-pred-post">\[\begin{equation}
p(\tilde{y} \mid y) = \int p(\tilde{y} \mid \theta) p(\theta \mid y) d\theta.
\tag{1.1}
\end{equation}\]</span></p>
</div>
<p>La <a href="#eq:dist-pred-post">(1.1)</a> descrive la nostra incertezza sui dati previsti futuri, tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati.</p>
<div id="un-esempio-concreto" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Un esempio concreto</h2>
<p>Consideriamo ancora il campione di pazienti clinici depressi di <span class="citation">Zetsche, Bürkner, and Renneberg (<a href="#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span>. Supponiamo di volere osservare in futuro altri 20 pazienti clinici. Sia <span class="math inline">\(\tilde{y} \in \{0, 1, \dots, 20\}\)</span> il numero di pazienti che, tra i nuovi pazienti futuri, manifestano una depressione grave. Se vogliamo fare predizioni su <span class="math inline">\(\tilde{y}\)</span> dobbiamo iniziare a riconoscere il fatto che i valori nell’intervallo [0, 20] non hanno tutti la stessa credibilità. Infatti, <span class="math inline">\(\tilde{y}\)</span> è una v.c. binomiale. Dunque sappiamo che <span class="math inline">\(\tilde{Y} \mid \theta \sim \Bin(20, \theta)\)</span> con densità</p>
<p><span class="math display" id="eq:post-yprime">\[\begin{equation}
p(y&#39;\mid \theta) = p(Y&#39; = y&#39; \mid \theta) = \binom{20}{y&#39;} \theta^{y&#39;}(1-\theta)^{20 - y&#39;} \; .
\tag{1.2}
\end{equation}\]</span></p>
<p>
È dunque chiaro che la v.c. <span class="math inline">\(Y&#39;\)</span> dipende da <span class="math inline">\(\theta\)</span>. Ma <span class="math inline">\(\theta\)</span> è essa stessa una variabile casuale. La <em>potenziale</em> distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, alla luce dei dati del campione osservato (<span class="math inline">\(y = 14\)</span>), è una <span class="math inline">\(\Beta(25, 15)\)</span> – questa distribuzione descrive la plausibilità relativa a posteriori dei valori <span class="math inline">\(\theta\)</span>. Per trovare la verosimiglianza relativa dei valori <span class="math inline">\(\tilde{y}\)</span> per le previste future 20 osservazioni è necessario applicare la <a href="#eq:dist-pred-post">(1.1)</a>:</p>
<p><span class="math display" id="eq:post-yprime-y17">\[\begin{align}
p(\tilde{y} \mid y = 17) = \int_0^1 p(\tilde{y} \mid \theta) p(\theta \mid y = 17) d\theta.
\tag{1.3}
\end{align}\]</span></p>
<p>
In parole, ciò significa che dobbiamo “sommare” la funzione <span class="math inline">\(p(\tilde{y} \mid \theta)\)</span> assegnando a <span class="math inline">\(\theta\)</span> tutti i valori possibili in [0, 1], ponderando ciascuno di questi “addendi” con un peso corrispondente alla verosimiglianza di <span class="math inline">\(\theta\)</span> nella distribuzione <span class="math inline">\(p(\theta \mid y = 17)\)</span>.</p>
<p>
Per il modello binomiale con una distribuzione a priori Beta è semplice ricavare analiticamente la distribuzione predittiva a posteriori:</p>
<p><span class="math display" id="eq:post-yprime-an-sol-betabin">\[\begin{align}
p(\tilde{y} \mid y) &amp;= \int_0^1 p(\tilde{y} \mid \theta)
p(\theta \mid y)\, d\theta \notag\\
 &amp;= \int_0^1 \begin{pmatrix}\tilde{n}\\\tilde{y}\end{pmatrix}
 \theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \Beta(a+y,b+n-y) \, d\theta \notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \int_0^1 \theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \frac{1}{B(a+y, b+n-y)}\theta^{a+y-1}(1-\theta)^{b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{1}{B(a+y, b+n-y)}\int_0^1 \theta^{\tilde{y}+a+y-1}(1-\theta)^{\tilde{n}-\tilde{y}+b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{B(\tilde{y}+a+y,b+n-y+\tilde{n}-\tilde{y})}{B(a+y, b+n-y)} 
\tag{1.4}
\end{align}\]</span></p>
<p>Per il caso presente, otteniamo:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Beta Binomial Predictive distribution function</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># https://rpubs.com/FJRubio/BetaBinomialPred</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>BetaBinom <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(rp){</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  log_val <span class="ot">&lt;-</span> <span class="fu">lchoose</span>(np, rp) <span class="sc">+</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lbeta</span>(rp<span class="sc">+</span>a<span class="sc">+</span>y, b<span class="sc">+</span>n<span class="sc">-</span>y<span class="sc">+</span>np<span class="sc">-</span>rp) <span class="sc">-</span> </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lbeta</span>(a<span class="sc">+</span>y, b<span class="sc">+</span>n<span class="sc">-</span>y)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">exp</span>(log_val))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span>; y <span class="ot">&lt;-</span> <span class="dv">17</span>; a <span class="ot">&lt;-</span> <span class="dv">25</span>; b <span class="ot">&lt;-</span> <span class="dv">15</span>; np <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">heads =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">pmf =</span> <span class="fu">BetaBinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(heads), <span class="at">y =</span> pmf)) <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">round</span>(pmf, <span class="dv">2</span>), <span class="at">y =</span> pmf <span class="sc">+</span> <span class="fl">0.01</span>),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">3</span>,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="dv">0</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Distribuzione predittiva a posteriori&quot;</span>,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;y&#39;&quot;</span>,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;P(Y = y&#39; | Data)&quot;</span>) </span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-2-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Nel caso dell’esempio che stiamo discutendo, la distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> è simile alla distribuzione binomiale di parametro <span class="math inline">\(\theta = 0.63\)</span> (anche se non è identica ad essa). In particolare, la <span class="math inline">\(p(\tilde{y} \mid y)\)</span> ha una varianza maggiore di <span class="math inline">\(\Bin(\tilde{n} = 20, \theta = 0.63)\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">heads =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">pmf =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">size =</span> <span class="dv">20</span>, <span class="at">prob =</span> <span class="fl">0.63</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(heads), <span class="at">y =</span> pmf)) <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">round</span>(pmf,<span class="dv">2</span>), <span class="at">y =</span> pmf <span class="sc">+</span> <span class="fl">0.01</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">3</span>,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="dv">0</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;p(y | theta = 0.63)&quot;</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;y&quot;</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;probability&quot;</span>) </span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-3-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Questa maggiore varianza riflette le due fonti di incertezza che sono presenti nella <a href="#eq:dist-pred-post">(1.1)</a>: l’incertezza sul valore del parametro (descritta dalla distribuzione a posteriori) e l’incertezza dovuta alla variabilità campionaria (descritta dalla funzione di verosimiglianza).</p>
<p>
Possiamo dunque concludere che, nel caso venissero osservati 20 nuovi pazienti clinici, il numero più plausibile di pazienti che manifestano una depressione severa (secondo il BDI-II) è 12, anche se è ragionevole aspettarsi un numero compreso, diciamo, tra 8 e 16.</p>
<p>
Una volta trovata la distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> diventa possibile rispondere a domande come: qual è la probabilità che almeno 10 dei 20 pazienti futuri mostrino una depressione grave, <span class="math inline">\(P(\tilde{Y} \geq 10 \mid Y = 17)\)</span>? Oppure: quanti dei 20 pazienti futuri ci possiamo aspettare che mostrino una depressione grave, <span class="math inline">\(\E(\tilde{Y} \mid Y = 17)\)</span>?</p>
<p>
Rispondere a domande di questo tipo è possibile, avendo a disposizione la <a href="#eq:post-yprime-an-sol-betabin">(1.4)</a>, ma richiede un po’ di lavoro – non ci sono funzioni R che svolgano questi calcoli per noi. Tuttavia, non è importante imparare a risolvere problemi di questo tipo perché, in generale, anche per problemi solo leggermente più complessi di quello discusso qui, non disponiamo di una espressione analitica della distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> [come nel caso della <a href="#eq:post-yprime-an-sol-betabin">(1.4)</a>]. Invece, in generale è necessario fare affidamento sulla simulazione MCMC per ottenere in maniera numerica una approssimazione della distribuzione predittiva a posteriori. In tali circostanze, è molto più facile trovare risposta a domande come le precedenti.</p>
</div>
<div id="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Metodi MCMC per la distribuzione predittiva a posteriori</h2>
<p>I Paragrafi precedenti hanno illustrato la teoria statistica alla base dell’analisi bayesiana della distribuzione a posteriori. Quando lavoriamo con modelli semplici come il modello Beta-Binomiale, possiamo implementare direttamente le teoria che sta alla base del modello, ovvero possiamo calcolare in maniera esatta gli intervalli di credibilità, le probabilità a posteriori e le proprietà della distribuzione predittiva a posteriori.</p>
<p>Tuttavia, espressioni analitiche che consentono una soluzione esatta ai problemi elencati sopra sono disponibili solo per modelli molto semplici, come ad esempio quello Beta-Binomiale. In generale, dobbiamo ricorrere ai metodi di campionamento MCMC per ottenere una approssimazione numerica della distribuzione a posteriori. In tali circostanze, sono stati messi a punto dei metodi che consentono di trovare una approsimazione anche della distribuzione predittiva a posteriori. Dunque, per rispondere alle domande di interesse non sarà necessario applicare delle formule ma potremo invece usare delle funzioni R.</p>
<p>Consideriamo nuovamente il codice Stan per una proporzione che abbiamo discusso nel Capitolo <a href="#mod-binom"><strong>??</strong></a>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">=</span> <span class="st">&quot;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0, upper=1&gt; y[N];</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0, upper=1&gt; theta;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="st">  theta ~ beta(2, 2);</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ bernoulli(theta);</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="st">  int y_rep[N];</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="st">  real log_lik[N];</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N) {</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = bernoulli_rng(theta);</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="st">    log_lik[n] = bernoulli_lpmf(y[n] | theta);</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/oneprop1.stan&quot;</span>)</span></code></pre></div>
<p>Utilizzando la notazione di <span class="citation">Gelman, Hwang, and Vehtari (<a href="#ref-gelman2014understanding" role="doc-biblioref">2014</a>)</span>, chiamiamo <span class="math inline">\(y^{rep}\)</span> i dati previsti futuri che potrebbero venire osservati se l’esperimento casuale che ha prodotto <span class="math inline">\(y\)</span> venisse ripetuto, ovvero una realizzazione futura del modello statistico con gli stessi valori dei parametri <span class="math inline">\(\theta\)</span> che hanno prodotto <span class="math inline">\(y\)</span>. <span class="citation">Gelman, Hwang, and Vehtari (<a href="#ref-gelman2014understanding" role="doc-biblioref">2014</a>)</span> distinguono <span class="math inline">\(y^{rep}\)</span> (repliche sotto lo stesso modello statistico) da <span class="math inline">\(\tilde{y}\)</span>, che corrisponde invece ad un effettivo campione empirico di dati osservato in qualche futura occasione.</p>
<p>
Quando l’analisi bayesiana viene svolta mediante metodi MCMC, una stima della distribuzione predittiva a posteriori si ottiene nel modo seguente:</p>
<ul>
<li>campionare <span class="math inline">\(\theta_i \sim p(\theta \mid y)\)</span>, ovvero campionare un valore del parametro dalla distribuzione a posteriori;</li>
<li>campionare <span class="math inline">\(y^{rep} \sim p(y^{rep} \mid \theta_i)\)</span>, ovvero campionare il valore di un’osservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.</li>
</ul>
<p>Questo processo in due fasi riflette le due fonti di incertezza che sono presenti: l’<em>incertezza sul valore del parametro</em> (riflessa dalla distribuzione a posteriori) e l’<em>incertezza dovuta alla variabilità campionaria</em> (riflessa dalla funzione di verosimiglianza). Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria (ma non in pratica) potrebbe essere ottenuta per via analitica.</p>
<p>Le istruzioni necessarie per simulare <span class="math inline">\(y^{rep}\)</span> (ovvero, <code>y_rep[n] = bernoulli_rng(theta);</code> sono state aggiunte nel blocco <code>generated quantities</code> del codice Stan.</p>
<p>I dati dell’esempio che stiamo discutendo sono:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">30</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">17</span>), <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">13</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>
Compiliamo il codice Stan:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;oneprop1.stan&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span></code></pre></div>
<p>
ed eseguiamo il campionamento MCMC:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 4L,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Running MCMC with <span class="dv">4</span> parallel chains...</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">1</span> finished <span class="cf">in</span> <span class="fl">0.2</span> seconds.</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">2</span> finished <span class="cf">in</span> <span class="fl">0.2</span> seconds.</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">3</span> finished <span class="cf">in</span> <span class="fl">0.2</span> seconds.</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Chain <span class="dv">4</span> finished <span class="cf">in</span> <span class="fl">0.1</span> seconds.</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> All <span class="dv">4</span> chains finished successfully.</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Mean chain execution time<span class="sc">:</span> <span class="fl">0.2</span> seconds.</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cn">FALSE</span> Total execution time<span class="sc">:</span> <span class="fl">0.3</span> seconds.</span></code></pre></div>
<p>
Per comodità, trasformiamo l’oggetto <code>fit</code> in un oggetto di classe <code>stanfit</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit<span class="sc">$</span><span class="fu">output_files</span>())</span></code></pre></div>
<p>
L’esatta distribuzione a posteriori è una Beta(19, 15):</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summarize_beta_binomial</span>(<span class="at">alpha =</span> <span class="dv">2</span>, <span class="at">beta =</span> <span class="dv">2</span>, <span class="at">y =</span> <span class="dv">17</span>, <span class="at">n =</span> <span class="dv">30</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       model alpha beta      mean   mode         var</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     prior     2    2 0.5000000 0.5000 0.050000000</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 posterior    19   15 0.5588235 0.5625 0.007043994</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           sd</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.22360680</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.08392851</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_beta</span>(<span class="at">alpha =</span> <span class="dv">19</span>, <span class="at">beta =</span> <span class="dv">15</span>) <span class="sc">+</span> </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lims</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-10-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
L’approssimazione della distribuzione a posteriori per <span class="math inline">\(\theta\)</span> ottenuta mediante la simulazione MCMC è</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_dens</span>(stanfit, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>) <span class="sc">+</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lims</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-11-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
La funzione <code>tidy()</code> nel pacchetto <code>broom.mixed</code> fornisce alcune utili statistiche per i 16000 valori della catena Markov memorizzati in <code>stanfit</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>broom.mixed<span class="sc">::</span><span class="fu">tidy</span>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  stanfit, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">conf.int =</span> <span class="cn">TRUE</span>, </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">conf.level =</span> <span class="fl">0.95</span>, </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 5</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term  estimate std.error conf.low conf.high</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 theta    0.560    0.0839    0.390     0.718</span></span></code></pre></div>
<p>
laddove, per esempio, la media esatta della corretta distribuzione a posteriori è</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="dv">19</span> <span class="sc">/</span> (<span class="dv">19</span> <span class="sc">+</span> <span class="dv">15</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.5588235</span></span></code></pre></div>
<p>
La funzione <code>tidy()</code> non consente di calcolare altre statistiche descrittive, oltre alla media. Ma questo risultato può essere ottenuto direttamente utilizzando i valori delle catene di Markov. Iniziamo ad esaminare il contenuto dell’oggetto <code>stanfit</code>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>list_of_draws <span class="ot">&lt;-</span> <span class="fu">extract</span>(stanfit)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">names</span>(list_of_draws))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;theta&quot;   &quot;y_rep&quot;   &quot;log_lik&quot; &quot;lp__&quot;</span></span></code></pre></div>
<p>
Possiamo estrarre i campioni della distribuzione a posteriori nel modo seguente:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(list_of_draws<span class="sc">$</span>theta)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.504220 0.507240 0.597812 0.453156 0.552692 0.540191</span></span></code></pre></div>
<p>
Creiamo un data.frame con le stime a posteriori <span class="math inline">\(\hat{\theta}\)</span>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta =</span> list_of_draws<span class="sc">$</span>theta</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>
Le statistiche descrittive della distribuzione a posteriori possono ora essere ottenute usando direttamente i valori <span class="math inline">\(\hat{\theta}\)</span>:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">post_mean =</span> <span class="fu">mean</span>(theta), </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">post_median =</span> <span class="fu">median</span>(theta),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">post_mode =</span> <span class="fu">sample_mode</span>(theta),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower_95 =</span> <span class="fu">quantile</span>(theta, <span class="fl">0.025</span>),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper_95 =</span> <span class="fu">quantile</span>(theta, <span class="fl">0.975</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   post_mean post_median post_mode  lower_95  upper_95</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.5593925    0.560318 0.5621779 0.3895725 0.7184689</span></span></code></pre></div>
<p>
È anche possibile calcolare, ad esempio, la probabilità di <span class="math inline">\(\hat{\theta} &gt; 0.5\)</span>:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">exceeds =</span> theta <span class="sc">&gt;</span> <span class="fl">0.50</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">tabyl</span>(exceeds)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  exceeds     n percent</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    FALSE  3824   0.239</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     TRUE 12176   0.761</span></span></code></pre></div>
<p>Occupiamoci ora della distribuzione predittiva a posteriori.</p>
<p>
Usando l’oggetto <code>stanfit</code> creiamo <code>y_bern</code>:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>y_bern <span class="ot">&lt;-</span> list_of_draws<span class="sc">$</span>y_rep</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(y_bern)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 16000    30</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(y_bern)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [1,]    0    0    0    0    0    1    1    1    1</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [2,]    1    1    1    1    0    1    1    0    1</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [3,]    1    1    0    1    1    1    1    1    0</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [4,]    0    0    1    0    0    0    0    0    0</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [5,]    0    1    1    0    0    1    1    0    0</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [6,]    1    1    1    1    1    1    0    1    1</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; iterations [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17]</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [1,]     1     1     0     1     0     0     1     1</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [2,]     0     1     0     1     0     0     0     0</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [3,]     0     0     1     1     1     0     0     1</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [4,]     0     1     1     1     1     1     0     1</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [5,]     1     0     0     1     1     1     0     0</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [6,]     1     1     1     1     0     1     1     1</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; iterations [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [1,]     1     0     1     1     1     0     0     1</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [2,]     1     0     1     0     1     1     0     0</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [3,]     1     1     0     1     1     1     0     0</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [4,]     1     1     1     0     1     1     0     0</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [5,]     1     1     0     0     1     1     0     0</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [6,]     0     1     0     1     0     1     1     0</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           </span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; iterations [,26] [,27] [,28] [,29] [,30]</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [1,]     1     1     1     1     1</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [2,]     0     0     1     0     0</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [3,]     1     1     0     1     0</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [4,]     0     0     1     0     1</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [5,]     1     0     1     1     1</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [6,]     0     1     1     0     0</span></span></code></pre></div>
<p>Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga di <code>y_bern</code> include 30 colonne, ciascuna delle quali è una stima di un nuovo futuro valore possibile <span class="math inline">\(y_i, \in \{0, 1\}\)</span>. Per ottenere <code>y_rep</code>, ovvero, il numero previsto di “successi” in nuove future <span class="math inline">\(N = 30\)</span> prove è sufficiente calcolare la somma dei valori di ciascuna riga. Ripetendo questa operazione per tutte le 16000 righe otteniamo una stima della distribuzione predittiva a posteriori:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">y_rep =</span> <span class="fu">rowSums</span>(y_bern)) <span class="sc">%&gt;%</span> </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y_rep)) <span class="sc">+</span> </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_count</span>()</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-20-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="posterior-predictive-checks" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Posterior predictive checks</h3>
<p>La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti <em>Posterior Predictive Checks</em> (PPC). I PPC vengono utilizzati per valutare l’<em>accuratezza predittiva</em> del modello, ovvero per confrontare con metodi grafici la distribuzione dei dati osservati <span class="math inline">\(y\)</span> con la stima della distribuzione predittiva a posteriori <span class="math inline">\(p(y^{rep} \mid y)\)</span>. Confrontando visivamente gli aspetti chiave dei dati previsti futuri <span class="math inline">\(y^{rep}\)</span> e dei dati osservati <span class="math inline">\(y\)</span> possiamo determinare rapidamente se il modello è adeguato. Se il modello si adatta bene ai dati, allora la distribuzione di <span class="math inline">\(y^{rep}\)</span> è molto simile alla distribuzione dei dati osservati. Con altre parole, i dati osservati devono sembrare plausibili alla luce della distribuzione predittiva a posteriori.</p>
<p>Oltre al confronto tra le distribuzioni di <span class="math inline">\(y\)</span> e <span class="math inline">\(y^{rep}\)</span> è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni <span class="math inline">\(y^{rep}\)</span>, e le corrispondenti statistiche descrittive calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo. Ma confronti di questo tipo sono possibili per qualunque statistica descrittiva. Questi confronti sono appunto chiamati PPC.</p>
<p>Per l’esempio presente, una volta eseguito il campionamento MCMC e ottenuto un oggetto di classe <code>stanfit</code>, è possibile usare le funzionalità del pacchetto <code>bayesplot</code> per eseguire i PPC. Nel caso presente, il campione di dati ha dimensioni esigue, per cui i PPC rifletteranno la grande incertenzza dell’inferenza.</p>
<p>
Dall’oggetto <code>stanfit</code> così trovato estraiamo <span class="math inline">\(y^{rep}\)</span>:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>y_rep <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">&quot;y_rep&quot;</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(y_rep)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 16000    30</span></span></code></pre></div>
<p>
Qui sotto esaminiamo la distribuzione <span class="math inline">\(y\)</span> insieme alla distribuzione di 8 campioni <span class="math inline">\(y^{rep}\)</span>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_hist</span>(data_list<span class="sc">$</span>y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>, ], <span class="at">binwidth =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-22-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Vediamo che la corrispondenza tra le due distribuzioni, <span class="math inline">\(y\)</span> e <span class="math inline">\(y^{rep}\)</span>, è solo parziale.</p>
<p>
Il confronto è più facile se sovrapponiamo graficamente la funzione di densità empirica di <span class="math inline">\(y\)</span> e quella di un insieme di campioni <span class="math inline">\(y^{rep}\)</span> (qui 50):</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(data_list<span class="sc">$</span>y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ])</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-23-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Anche qui vediamo che c’è una corrispondenza solo approssimativa tra la funzione di densità empirica di <span class="math inline">\(y\)</span> e quella di un insieme di campioni <span class="math inline">\(y^{rep}\)</span> – ciò è dovuto al fatto che il campione è molto piccolo.</p>
<p>
La distribuzione predittiva a posteriori è comunque in grado di rappresentare accuratamente la media di <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat</span>(data_list<span class="sc">$</span>y, y_rep, <span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-24-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Lo stesso si può dire della varianza:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat</span>(data_list<span class="sc">$</span>y, y_rep, <span class="at">stat =</span> <span class="st">&quot;var&quot;</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-25-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Nell’esempio successivo vedremo come i PPC possano fornirci delle indicazioni sulla mancanza di adattamento del modello ai dati quando viene considerato un campione più grande.</p>
</div>
<div id="ppc-per-il-modello-di-poisson" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> PPC per il modello di Poisson</h3>
<p>Le istruzioni R fornite qui sotto sono state recuperate dalla seguente <a href="http://avehtari.github.io/BDA_R_demos/demos_rstan/ppc/poisson-ppc.html#">pagina web</a>. Nell’esempio discusso da Jonah Gabry e Aki Vehtari vengono usati i seguenti dati:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(0L, 3L, 5L, 0L, 4L, 7L, 4L, 2L, 3L, </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>       6L, 7L, 0L, 0L, 3L, 7L, 5L, 5L, 0L, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>       4L, 0L, 4L, 4L, 6L, 3L, 7L, 5L, 3L, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>       0L, 0L, 2L, 0L, 1L, 0L, 1L, 5L, 4L, </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>       4L, 2L, 3L, 6L, 4L, 5L, 0L, 7L, 7L, </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>       4L, 4L, 4L, 0L, 6L, 1L, 5L, 6L, 5L, </span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>       6L, 7L, 3L, 6L, 2L, 3L, 0L, 2L, 0L, </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>       6L, 6L, 0L, 3L, 4L, 4L, 5L, 5L, 0L, </span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>       5L, 7L, 5L, 5L, 6L, 4L, 2L, 3L, 4L, </span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>       6L, 4L, 6L, 6L, 4L, 0L, 6L, 5L, 5L, </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>       7L, 0L, 1L, 6L, 7L, 0L, 5L, 0L, 0L, </span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>       5L, 6L, 5L, 1L, 0L, 7L, 1L, 2L, 6L, </span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>       5L, 4L, 0L, 4L, 0L, 4L, 4L, 6L, 3L, </span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>       0L, 0L, 3L, 3L, 4L, 2L, 5L, 3L, 4L, </span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>       3L, 2L, 5L, 2L, 4L, 4L, 0L, 2L, 7L, </span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>       5L, 7L, 5L, 5L, 7L, 7L, 0L, 4L, 6L, </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>       0L, 4L, 6L, 7L, 4L, 0L, 4L, 1L, 5L, </span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>       0L, 3L, 5L, 7L, 6L, 0L, 5L, 5L, 6L, </span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>       7L, 6L, 7L, 3L, 4L, 3L, 7L, 7L, 2L, </span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>       5L, 4L, 5L, 5L, 0L, 6L, 2L, 4L, 5L, </span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>       4L, 0L, 0L, 5L, 5L, 7L, 7L, 0L, 3L, </span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>       0L, 3L, 3L, 6L, 1L, 4L, 2L, 0L, 4L, </span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>       7L, 5L, 5L, 0L, 3L, 7L, 0L, 6L, 6L, </span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>       4L, 1L, 6L, 7L, 6L, 0L, 3L, 6L, 4L, </span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>       7L, 0L, 5L, 5L, 4L, 0L, 0L, 2L, 4L, </span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>       6L, 0L, 5L, 0L, 2L, 7L, 2L, 7L, 5L, </span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>       4L, 6L, 2L, 4L, 0L, 4L, 0L, 0L, 3L, </span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>       5L, 4L, 3L, 5L, 5L, 7L, 7L, 0L, 6L, </span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>       4L, 5L, 1L, 5L, 3L, 5L, 5L, 5L, 0L, </span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>       2L, 7L, 6L, 2L, 3L, 2L, 5L, 4L, 7L, </span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>       6L, 7L, 3L, 3L, 4L, 4L, 6L, 4L, 6L, </span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>       7L, 1L, 5L, 6L, 3L, 3L, 6L, 3L, 4L, </span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>       0L, 7L, 0L, 3L, 6L, 5L, 0L, 0L, 0L, </span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>       5L, 4L, 4L, 0L, 4L, 7L, 5L, 5L, 3L, </span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>       3L, 0L, 0L, 5L, 4L, 0L, 7L, 6L, 0L, </span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>       6L, 2L, 0L, 6L, 1L, 0L, 4L, 0L, 4L, </span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>       3L, 0L, 4L, 5L, 5L, 7L, 6L, 6L, 5L, </span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>       4L, 7L, 0L, 6L, 4L, 7L, 7L, 5L, 0L, </span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>       1L, 4L, 7L, 6L, 4L, 5L, 4L, 7L, 2L, </span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>       5L, 2L, 6L, 3L, 2L, 7L, 4L, 3L, 4L, </span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>       6L, 6L, 6L, 6L, 7L, 1L, 0L, 0L, 7L, </span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>       7L, 4L, 2L, 4L, 5L, 5L, 7L, 4L, 1L, </span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>       7L, 6L, 5L, 6L, 5L, 4L, 0L, 0L, 7L, </span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>       0L, 0L, 5L, 6L, 6L, 3L, 6L, 0L, 0L, </span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>       0L, 4L, 4L, 3L, 0L, 7L, 5L, 4L, 2L, </span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>       7L, 0L, 4L, 0L, 0L, 2L, 4L, 5L, 0L, </span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>       4L, 2L, 5L, 2L, 0L, 6L, 6L, 3L, 6L, </span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>       0L, 2L, 5L, 0L, 0L, 0L, 6L, 0L, 0L, </span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>       6L, 5L, 4L, 6L, 4L, 5L, 5L, 4L, 0L, </span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>       3L, 4L, 3L, 3L, 5L, 3L, 4L, 5L, 7L, </span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>       0L, 0L, 1L, 4L, 6L, 3L, 5L, 7L, 6L, </span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>       6L, 5L, 0L, 5L, 4L, 0L, 0L, 2L, 6L, </span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>       0L, 6L, 0L, 4L, 5L, 6L, 3L, 4L, 2L, </span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>       3L, 4L, 0L, 5L, 0L, 0L, 0L, 0L, 3L, </span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>       4L, 7L, 6L, 7L, 7L, 3L, 4L, 4L, 7L, </span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>       4L, 5L, 2L, 5L, 6L)</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span></code></pre></div>
<p>
Per questi dati sembra appropriato un modello di Poisson.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(y)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-27-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Un istogramma di un campione casuale della stessa ampiezza di <span class="math inline">\(y\)</span> tratto dalla distribuzione di Poisson è il seguente:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rpois</span>(N, <span class="fu">mean</span>(y))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(x)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-28-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
È chiaro che i due istogrammi sono molto diversi.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>plotdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">value =</span> <span class="fu">c</span>(y, x), </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">variable =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Dati osservati&quot;</span>, <span class="st">&quot;Dati dalla distribuzione</span><span class="sc">\n</span><span class="st"> di Poisson&quot;</span>), <span class="at">each =</span> N)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plotdata, <span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">color =</span> variable)) <span class="sc">+</span> </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_freqpoly</span>(<span class="at">binwidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">&quot;&quot;</span>, <span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="fu">max</span>(x,y)) <span class="sc">+</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">&quot;&quot;</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;gray30&quot;</span>, <span class="st">&quot;purple&quot;</span>))</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-29-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Anche se già sospettiamo che non sarà un buon modello per questi dati, è comunque una buona idea iniziare adattando ai dati il modello più semplice, ovvero quello di Poisson. Partendo da lì possiamo poi cercare di capire in che modo il modello è inadeguato.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=1&gt; N;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; y[N];</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; lambda;</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="st">  lambda ~ exponential(0.2);</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ poisson(lambda);</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="st">  int y_rep[N];</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N) {</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="st">    y_rep[n] = poisson_rng(lambda);</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/code_poisson.stan&quot;</span>)</span></code></pre></div>
<p>
Creiamo un oggetto di tipo <code>list</code> dove inserire i dati:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>data_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(y)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>
Adattiamo il modello ai dati:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;code_poisson.stan&quot;</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 4L,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Running MCMC with 4 parallel chains...</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 1 finished in 0.9 seconds.</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 2 finished in 0.9 seconds.</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 3 finished in 0.9 seconds.</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 4 finished in 0.9 seconds.</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Mean chain execution time: 0.9 seconds.</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Total execution time: 1.0 seconds.</span></span></code></pre></div>
<p>
In questo modo otteniamo la seguente stima del parametro <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>fit<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">&quot;lambda&quot;</span>))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 10</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   variable  mean median     sd    mad    q5   q95  rhat</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 lambda    3.66   3.66 0.0830 0.0831  3.53  3.80  1.00</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 2 more variables: ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;</span></span></code></pre></div>
<p>
Confrontiamo <span class="math inline">\(\lambda\)</span> con la media di <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 3.662</span></span></code></pre></div>
<p>
Il modello trova la media giusta, ma, come vedremo nel seguito, il modello non è comunque adeguato a prevedere le altre proprietà di <span class="math inline">\(y\)</span>.</p>
<p>
Trasformiamo l’oggetto <code>fit</code> in un oggetto <code>stanfit</code>:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit<span class="sc">$</span><span class="fu">output_files</span>())</span></code></pre></div>
<p>
La distribuzione a posteriori di <span class="math inline">\(\lambda\)</span> è</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>lambda_draws <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(lambda_draws, <span class="at">prob =</span> <span class="fl">0.95</span>) <span class="co"># color 95% interval</span></span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-36-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
Estraiamo <span class="math inline">\(y^{rep}\)</span> dall’oggetto <code>stanfit</code>:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>y_rep <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit, <span class="at">pars =</span> <span class="st">&quot;y_rep&quot;</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(y_rep) </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 16000   500</span></span></code></pre></div>
<div id="confronto-tra-listogramma-di-y-e-gli-istogrammi-di-diversi-campioni-yrep" class="section level4" number="1.2.2.1">
<h4><span class="header-section-number">1.2.2.1</span> Confronto tra l’istogramma di <span class="math inline">\(y\)</span> e gli istogrammi di diversi campioni <span class="math inline">\(y^{rep}\)</span></h4>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_hist</span>(y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>, ], <span class="at">binwidth =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-38-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="confronto-tra-la-funzione-di-densità-empirica-di-y-e-quella-di-diversi-campioni-yrep" class="section level4" number="1.2.2.2">
<h4><span class="header-section-number">1.2.2.2</span> Confronto tra la funzione di densità empirica di <span class="math inline">\(y\)</span> e quella di diversi campioni <span class="math inline">\(y^{rep}\)</span></h4>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ])</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-39-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="ppc-per-la-media-e-la-deviazine-standard" class="section level4" number="1.2.2.3">
<h4><span class="header-section-number">1.2.2.3</span> PPC per la media e la deviazine standard</h4>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat_2d</span>(y, y_rep, <span class="at">stat =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>))</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-40-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Mentre la media viene riprodotta accuratamente dal modello (come avevamo visto sopra), ciò non è vero per la deviazione stanard dei dati. La domanda è quale sia l’origine di questa mancanza di adattamento.</p>
</div>
<div id="confronto-tra-la-proporzione-di-zeri-in-y-e-nei-campioni-yrep" class="section level4" number="1.2.2.4">
<h4><span class="header-section-number">1.2.2.4</span> Confronto tra la proporzione di zeri in <span class="math inline">\(y\)</span> e nei campioni <span class="math inline">\(y^{rep}\)</span></h4>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>prop_zero <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">mean</span>(x <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">prop_zero</span>(y))</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.202</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat</span>(y, y_rep, <span class="at">stat =</span> <span class="st">&quot;prop_zero&quot;</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-42-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Da questo PPC risulta chiaro che il modello non è assolutamente in grado di catturare la proporzione di casi nei quali la variabile <span class="math inline">\(Y\)</span> assume il valore 0. In altri termini, i dati presentano un’inflazione di valori 0 rispetto a quelli che sono previsti da un modello di Poisson. Questo è un problema che si verifica spesso nei dati empirici.</p>
</div>
<div id="poisson-hurdle-model" class="section level4" number="1.2.2.5">
<h4><span class="header-section-number">1.2.2.5</span> Poisson “hurdle” model</h4>
<p>Per ovviare il problema corrispondente all’inflazione di valori pari a 0, è possibile definire un modello di tipo “hurdle” che consente la presenza di una proporzione di valori pari a 0 maggiore di quanto normalmente previsto dalla distribuzione di Poisson. Senza entrare nei dettagli di come questo viene fatto, Gabry e Vehtari definiscono il seguente modello:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>modelString2 <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=1&gt; N;</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; y[N];</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="st">transformed data {</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="st">  int U = max(y);  // upper truncation point</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0,upper=1&gt; theta; // Pr(y = 0)</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; lambda; // Poisson rate parameter (if y &gt; 0)</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="st">  lambda ~ exponential(0.2);</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="st">  </span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N) {</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="st">    if (y[n] == 0) {</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="st">      target += log(theta);  // log(Pr(y = 0))</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="st">    } else {</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="st">      target += log1m(theta);  // log(Pr(y &gt; 0))</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a><span class="st">      y[n] ~ poisson(lambda) T[1,U];  // truncated poisson</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a><span class="st">  real log_lik[N];</span></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a><span class="st">  int y_rep[N];</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a><span class="st">  for (n in 1:N) {</span></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a><span class="st">    if (bernoulli_rng(theta)) {</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a><span class="st">      y_rep[n] = 0;</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a><span class="st">    } else {</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a><span class="st">      int w;  // temporary variable</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a><span class="st">      w = poisson_rng(lambda); </span></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a><span class="st">      while (w == 0 || w &gt; U)</span></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a><span class="st">        w = poisson_rng(lambda);</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a><span class="st">        </span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a><span class="st">      y_rep[n] = w;</span></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a><span class="st">    if (y[n] == 0) {</span></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a><span class="st">      log_lik[n] = log(theta);</span></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a><span class="st">    } else {</span></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a><span class="st">      log_lik[n] = log1m(theta)</span></span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a><span class="st">    + poisson_lpmf(y[n] | lambda)</span></span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a><span class="st">    - log_diff_exp(poisson_lcdf(U | lambda),</span></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a><span class="st">                       poisson_lcdf(0 | lambda));</span></span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString2, <span class="at">con =</span> <span class="st">&quot;code/code_poisson_hurdle.stan&quot;</span>)</span></code></pre></div>
<p>
Adattiamo il modello ai dati:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>file2 <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;code_poisson_hurdle.stan&quot;</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file2)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> mod2<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data_list,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 4L,</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Running MCMC with 4 parallel chains...</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 1 finished in 11.0 seconds.</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 2 finished in 11.4 seconds.</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 3 finished in 11.2 seconds.</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chain 4 finished in 11.4 seconds.</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; All 4 chains finished successfully.</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Mean chain execution time: 11.3 seconds.</span></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Total execution time: 11.8 seconds.</span></span></code></pre></div>
<p>
In questo caso otteniamo una stima di <span class="math inline">\(\lambda\)</span> diversa da quella ottenuta in precedenza:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">&quot;lambda&quot;</span>, <span class="st">&quot;theta&quot;</span>))</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 × 10</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   variable  mean median     sd    mad    q5   q95  rhat</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 lambda   5.30   5.30  0.162  0.162  5.04  5.57   1.00</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 theta    0.203  0.203 0.0179 0.0179 0.174 0.233  1.00</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 2 more variables: ess_bulk &lt;dbl&gt;, ess_tail &lt;dbl&gt;</span></span></code></pre></div>
<p>
Il parametro <span class="math inline">\(\theta\)</span> viene usato per modellizzare l’eccesso di valori 0.</p>
</div>
<div id="confronto-tra-le-distribuzioni-a-posteriori-di-lambda-per-i-due-modelli" class="section level4" number="1.2.2.6">
<h4><span class="header-section-number">1.2.2.6</span> Confronto tra le distribuzioni a posteriori di <span class="math inline">\(\lambda\)</span> per i due modelli</h4>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>stanfit2 <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit2<span class="sc">$</span><span class="fu">output_files</span>())</span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>lambda_draws2 <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit2, <span class="at">pars =</span> <span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lambda_fit1 =</span> lambda_draws[, <span class="dv">1</span>],</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">lambda_fit2 =</span> lambda_draws2[, <span class="dv">1</span>])</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(lambdas, <span class="at">prob =</span> <span class="fl">0.95</span>) <span class="co"># color 95% interval</span></span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-47-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="posterior-predictive-checks-1" class="section level4" number="1.2.2.7">
<h4><span class="header-section-number">1.2.2.7</span> Posterior predictive checks</h4>
<p>Rifacciamo i grafici esaminati in precedenza (e alcuni altri), ma questa volta eatraendo <span class="math inline">\(y^{rep}\)</span> da <code>fit2</code>:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>y_rep2 <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(stanfit2, <span class="at">pars =</span> <span class="st">&quot;y_rep&quot;</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_hist</span>(y, y_rep2[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>, ], <span class="at">binwidth =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-48-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>
In questo caso la distribuzione di <span class="math inline">\(y^{rep}\)</span> è molto simile alla distribuzione di <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(y, y_rep2[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, ])</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-49-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat</span>(y, y_rep2, <span class="at">stat =</span> <span class="st">&quot;prop_zero&quot;</span>)</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-50-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_stat_2d</span>(y, y_rep2, <span class="at">stat =</span> <span class="fu">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>))</span></code></pre></div>
<p><img src="046_ppc_files/figure-html/unnamed-chunk-51-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>In conclusione, l’accuratezza predittiva del modello “hurdle” è chiaramente migliore di quella del modello di Poisson.</p>
</div>
</div>
</div>
<div id="considerazioni-conclusive" class="section level2 unnumbered">
<h2>Considerazioni conclusive</h2>
<p>Questo capitolo abbiamo discusso i controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: i controlli predittivi a posteriori, quando suggeriscono un buon adattamento del modello alle caratterische dei dati previsti futuri <span class="math inline">\(y^{rep}\)</span>, non forniscono una forte evidenza della capacità del modello di generalizzarsi a nuovi campioni di dati. Infatti, una tale evidenza sulla generalizzabilità del modello può essere solo fornita da studi di <em>cross-validation</em>, ovvero da studi nei quali viene utilizzato un <em>nuovo</em> campione di dati. D’altra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo fornisce una forte evidenza di una errata specificazione del modello.</p>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. <span>“Understanding Predictive Information Criteria for Bayesian Models.”</span> <em>Statistics and Computing</em> 24 (6): 997–1016.
</div>
<div class="csl-entry">
Zetsche, Ulrike, Paul-Christian Bürkner, and Babette Renneberg. 2019. <span>“Future Expectations in Clinical Depression: <span>Biased</span> or Realistic?”</span> <em>Journal of Abnormal Psychology</em> 128 (7): 678–88.
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gelman2014understanding" class="csl-entry">
Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. <span>“Understanding Predictive Information Criteria for Bayesian Models.”</span> <em>Statistics and Computing</em> 24 (6): 997–1016.
</div>
<div id="ref-zetschefuture2019" class="csl-entry">
Zetsche, Ulrike, Paul-Christian Bürkner, and Babette Renneberg. 2019. <span>“Future Expectations in Clinical Depression: <span>Biased</span> or Realistic?”</span> <em>Journal of Abnormal Psychology</em> 128 (7): 678–88.
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/046_ppc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Science per psicologi.pdf", "Data Science per psicologi.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
