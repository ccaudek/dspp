<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi</title>
  <meta name="description" content="Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi" />
  
  <meta name="twitter:description" content="Capitolo 2 L’effetto della distribuzione a priori sulla distribuzione a posteriori | Data Science per psicologi si propone di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche presso l’Università degli Studi di Firenze. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2021-09-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> url: your book url like <span>https://bookdown.org/yihui/bookdown</span></a></li>
<li class="chapter" data-level="2" data-path="chapter-balance.html"><a href="chapter-balance.html"><i class="fa fa-check"></i><b>2</b> L’effetto della distribuzione a priori sulla distribuzione a posteriori</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-balance.html"><a href="chapter-balance.html#stessi-dati-ma-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>2.1</b> Stessi dati ma diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="2.2" data-path="chapter-balance.html"><a href="chapter-balance.html#dati-diversi-stessa-distribuzione-a-priori"><i class="fa fa-check"></i><b>2.2</b> Dati diversi, stessa distribuzione a priori</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-balance.html"><a href="chapter-balance.html#dati-diversi-e-diverse-distribuzioni-a-priori"><i class="fa fa-check"></i><b>2.3</b> Dati diversi e diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-balance.html"><a href="chapter-balance.html#collegare-le-intuizioni-alla-teoria"><i class="fa fa-check"></i><b>2.4</b> Collegare le intuizioni alla teoria</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter-balance" class="section level1" number="2">
<h1><span class="header-section-number">Capitolo 2</span> L’effetto della distribuzione a priori sulla distribuzione a posteriori</h1>
<p>La notazione <span class="math inline">\(p(\theta \mid y) \propto p(\theta) \ p(y \mid \theta)\)</span> rende particolarmente chiaro che la distribuzione a posteriori è un “miscuglio” della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori, cerchiamo di capire meglio cosa significa “mescolare” la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio fornito da <span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>. Nel fumetto di Alison Bechdel <em>The Rule</em>, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole <span class="citation">(<a href="#ref-Bechdel1986dykes" role="doc-biblioref">Bechdel 1986</a>)</span>:</p>
<ul>
<li>almeno due caratteri nel film devono essere donne;</li>
<li>queste due donne si parlano;</li>
<li>parlano di qualcosa altro oltre a parlare di qualche uomo.</li>
</ul>
<p>
Questi criteri costituiscono il <em>test di Bechdel</em> per la rappresentazione delle donne nei film. <span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> pongono la seguente domanda “Quale percentuale dei film che avete visto supera il test di Bechdel?”</p>
<p>Sia <span class="math inline">\(\pi \in [0, 1]\)</span> una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche — la femminista, l’ignara e l’ottimista — hanno opionioni diverse su <span class="math inline">\(\pi\)</span>. Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L’ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l’ottimista pensa che, in generale, le donne sono ben rappresentate all’interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di <span class="math inline">\(\pi\)</span>.</p>
<p>Abbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori <span class="math inline">\(\pi &lt; 0.5\)</span>, la distribuzione a priori <span class="math inline">\(\text{Beta}(5, 11)\)</span> riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la <span class="math inline">\(\text{Beta}(14,1)\)</span> pone la gran parte della massa della distribuzione a priori su valori <span class="math inline">\(\pi\)</span> prossimi a 1, e corrisponde quindi alle credenze a priori dell’amica ottimista. Infine, una <span class="math inline">\(\text{Beta}(1 ,1)\)</span> o <span class="math inline">\(Unif(0, 1)\)</span>, assegna lo stesso livello di plausibilità a tutti i valori <span class="math inline">\(\pi \in [0, 1]\)</span>, e corrisponde all’incertezza a priori dell’ignara.</p>
<p>Nell’esempio di <span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span>, le tre amiche decidano di rivedere un campione di <span class="math inline">\(n\)</span> film e di registrare <span class="math inline">\(y\)</span>, il numero di film che supera il test di Bechdel. Se <span class="math inline">\(y\)</span> corrisponde al numero di “successi” in un numero fisso di <span class="math inline">\(n\)</span> prove Bernoulliane i.i.d., allora la dipendenza di <span class="math inline">\(y\)</span> da <span class="math inline">\(\pi\)</span> viene specificata nei termini di un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello Beta-Binomiale</p>
<p><span class="math display">\[\begin{align}
Y \mid \pi &amp; \sim \text{Bin}(n, \pi)  \notag\\
\pi &amp; \sim \text{Beta}(\alpha, \beta) \notag
\end{align}\]</span></p>
<p>
che utilizza parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> diversi per la distribuzione a priori, il che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\pi \mid (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y).
\end{equation}\]</span></p>
<p><span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> si chiedono come le credenze a priori delle tre amiche influenzano le conclusioni a posteriori a cui esse giungono, dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l’influenza della distribuzione a priori sulla distribuzione a posteriori. Per rispondere a queste domande, <span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> consideriamo tre diversi scenari:</p>
<ul>
<li>gli stessi dati osservati, ma distribuzioni a priori diverse;</li>
<li>dati diversi, ma la stessa distribuzione a priori;</li>
<li>dati diversi e distribuzioni a priori diverse.</li>
</ul>
<div id="stessi-dati-ma-diverse-distribuzioni-a-priori" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Stessi dati ma diverse distribuzioni a priori</h2>
<p>Iniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter-balance.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(bechdel, <span class="at">package =</span> <span class="st">&quot;bayesrules&quot;</span>)</span>
<span id="cb1-2"><a href="chapter-balance.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">84735</span>)</span>
<span id="cb1-3"><a href="chapter-balance.html#cb1-3" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="ot">&lt;-</span> bechdel <span class="sc">%&gt;%</span> </span>
<span id="cb1-4"><a href="chapter-balance.html#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">20</span>)</span>
<span id="cb1-5"><a href="chapter-balance.html#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="chapter-balance.html#cb1-6" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="sc">%&gt;%</span> </span>
<span id="cb1-7"><a href="chapter-balance.html#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">3</span>)</span>
<span id="cb1-8"><a href="chapter-balance.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 × 3</span></span>
<span id="cb1-9"><a href="chapter-balance.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    year title      binary</span></span>
<span id="cb1-10"><a href="chapter-balance.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt; </span></span>
<span id="cb1-11"><a href="chapter-balance.html#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  2005 King Kong  FAIL  </span></span>
<span id="cb1-12"><a href="chapter-balance.html#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2  1983 Flashdance PASS  </span></span>
<span id="cb1-13"><a href="chapter-balance.html#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3  2013 The Purge  FAIL</span></span></code></pre></div>
<p>Di questi 20 film, solo il 45% (<span class="math inline">\(y\)</span> = 9) passa il test di Bechdel:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="chapter-balance.html#cb2-1" aria-hidden="true" tabindex="-1"></a>bechdel_20 <span class="sc">%&gt;%</span> </span>
<span id="cb2-2"><a href="chapter-balance.html#cb2-2" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">tabyl</span>(binary) <span class="sc">%&gt;%</span> </span>
<span id="cb2-3"><a href="chapter-balance.html#cb2-3" aria-hidden="true" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>(<span class="st">&quot;row&quot;</span>)</span>
<span id="cb2-4"><a href="chapter-balance.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  binary  n percent</span></span>
<span id="cb2-5"><a href="chapter-balance.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    FAIL 11    0.55</span></span>
<span id="cb2-6"><a href="chapter-balance.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    PASS  9    0.45</span></span>
<span id="cb2-7"><a href="chapter-balance.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Total 20    1.00</span></span></code></pre></div>
<p>Esaminiamo ora le tre distribuzioni a posteriori. Per la femminista abbiamo:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="chapter-balance.html#cb3-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb3-2"><a href="chapter-balance.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb3-3"><a href="chapter-balance.html#cb3-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="027_balance_prior_post_files/figure-html/unnamed-chunk-3-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="chapter-balance.html#cb4-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb4-2"><a href="chapter-balance.html#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb4-3"><a href="chapter-balance.html#cb4-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-4"><a href="chapter-balance.html#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       model alpha beta      mean      mode        var</span></span>
<span id="cb4-5"><a href="chapter-balance.html#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     prior     5   11 0.3125000 0.2857143 0.01263787</span></span>
<span id="cb4-6"><a href="chapter-balance.html#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 posterior    14   22 0.3888889 0.3823529 0.00642309</span></span>
<span id="cb4-7"><a href="chapter-balance.html#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           sd</span></span>
<span id="cb4-8"><a href="chapter-balance.html#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.11241827</span></span>
<span id="cb4-9"><a href="chapter-balance.html#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.08014418</span></span></code></pre></div>
<p>Per l’ottimista abbiamo:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="chapter-balance.html#cb5-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb5-2"><a href="chapter-balance.html#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb5-3"><a href="chapter-balance.html#cb5-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="027_balance_prior_post_files/figure-html/unnamed-chunk-5-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="chapter-balance.html#cb6-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb6-2"><a href="chapter-balance.html#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb6-3"><a href="chapter-balance.html#cb6-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-4"><a href="chapter-balance.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       model alpha beta      mean      mode         var</span></span>
<span id="cb6-5"><a href="chapter-balance.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     prior    14    1 0.9333333 1.0000000 0.003888889</span></span>
<span id="cb6-6"><a href="chapter-balance.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 posterior    23   12 0.6571429 0.6666667 0.006258503</span></span>
<span id="cb6-7"><a href="chapter-balance.html#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           sd</span></span>
<span id="cb6-8"><a href="chapter-balance.html#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.06236096</span></span>
<span id="cb6-9"><a href="chapter-balance.html#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.07911070</span></span></code></pre></div>
<p>Infine, per l’ignara troviamo</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="chapter-balance.html#cb7-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb7-2"><a href="chapter-balance.html#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb7-3"><a href="chapter-balance.html#cb7-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="027_balance_prior_post_files/figure-html/unnamed-chunk-7-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="chapter-balance.html#cb8-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">:::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb8-2"><a href="chapter-balance.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">9</span>, <span class="at">n =</span> <span class="dv">20</span></span>
<span id="cb8-3"><a href="chapter-balance.html#cb8-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-4"><a href="chapter-balance.html#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       model alpha beta      mean mode        var        sd</span></span>
<span id="cb8-5"><a href="chapter-balance.html#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751</span></span>
<span id="cb8-6"><a href="chapter-balance.html#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255</span></span></code></pre></div>
<p>Per calcolare la distribuzione a posteriori, ho qui usato le funzioni del pacchetto <code>bayesrules</code>. Ma nel caso Beta-Binomiale è facile trovafre i parametri della distribuzione a posteriori. Per esempio, nel caso della femminista, la distribuzione a posteriori è una Beta di parametri
<span class="math display">\[
\alpha_{post} = \alpha_{prior} + y = 5+9 = 14
\]</span>
e
<span class="math display">\[
\beta_{post} = \beta_{prior} + n - y = 11 + 20 - 9 = 22.
\]</span></p>
<p>L’aggiornamento bayesiano indica che le tre amiche ottengono valori per la media (o la moda) a posteriori per <span class="math inline">\(\pi\)</span> molto diversi. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d’accordo su qual è la proporzione di film che passano il test di Bechdel.</p>
<p>Questo non dovrebbe sorprenderci. L’amica ottimista aveva opinioni molto forti sul valore di <span class="math inline">\(\pi\)</span> e i <strong>pochi</strong> nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: crede ancora che i valori di <span class="math inline">\(\pi\)</span> superiori a 0.5 siano i più plausibili. Lo stesso si può dire, all’estremo opposto, dell’amica femminista: anche lei continua a credere che i valori di <span class="math inline">\(\pi\)</span> inferiori a 0.5 siano i più plausibili. Infine, l’ignara non aveva nessuna opinione a priori su <span class="math inline">\(\pi\)</span> e, anche dopo avere visto 20 film, con una proporzione osservata di successi pari a 0.45, continua a credere che il valore <span class="math inline">\(\pi\)</span> più plausibile sia quello intermedio, ovvero nell’intorno di 0.5.</p>
</div>
<div id="dati-diversi-stessa-distribuzione-a-priori" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Dati diversi, stessa distribuzione a priori</h2>
<p>Supponiamo che l’amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. Chiede a Maria, Anna e Sara di fare l’esperimento. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.</p>
<p>Per Maria, Anna e Sara, la credenza a priori su <span class="math inline">\(\pi\)</span> è la stessa: Beta(14, 1). Come diventano le tre distribuzioni a posteriori?</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="chapter-balance.html#cb9-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb9-2"><a href="chapter-balance.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb9-3"><a href="chapter-balance.html#cb9-3" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb9-4"><a href="chapter-balance.html#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="chapter-balance.html#cb9-5" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb9-6"><a href="chapter-balance.html#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb9-7"><a href="chapter-balance.html#cb9-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb9-8"><a href="chapter-balance.html#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="chapter-balance.html#cb9-9" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb9-10"><a href="chapter-balance.html#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb9-11"><a href="chapter-balance.html#cb9-11" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb9-12"><a href="chapter-balance.html#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="chapter-balance.html#cb9-13" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-9"></span>
<img src="027_balance_prior_post_files/figure-html/unnamed-chunk-9-1.png" alt="Aggiornamento bayesiano per Maria, Anna e Sara." width="95%" />
<p class="caption">
Figura 2.1: Aggiornamento bayesiano per Maria, Anna e Sara.
</p>
</div>
<p>Notiamo due cose. All’aumentare delle informazioni disponibili (ovvero, l’ampiezza del campione), la distribuzione a posteriori si allontana sempre più dalla distribuzione a priori, e si avvicina sempre più alla verosimiglianza. In secondo luogo, all’aumentare dell’ampiezza del campione, la varianza della distribuzione a posteriori diminuisce sempre di più, ovvero, diminuisce l’incertezza su quelli che sono i valori plausibili per <span class="math inline">\(\pi\)</span>.</p>
</div>
<div id="dati-diversi-e-diverse-distribuzioni-a-priori" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Dati diversi e diverse distribuzioni a priori</h2>
<p>Nella figura successiva esaminiamo la distribuzione a posteriori incrociando tre diversi set di dati (<span class="math inline">\(y\)</span> = 6, <span class="math inline">\(n\)</span> = 13;, <span class="math inline">\(y\)</span> = 29, <span class="math inline">\(n\)</span> = 63; <span class="math inline">\(y\)</span> = 66, <span class="math inline">\(n\)</span> = 99) con tre diverse distribuzioni a priori [Beta(14, 1), Beta(5, 11), Beta(1, 1)].</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter-balance.html#cb10-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-2"><a href="chapter-balance.html#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb10-3"><a href="chapter-balance.html#cb10-3" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-4"><a href="chapter-balance.html#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="chapter-balance.html#cb10-5" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-6"><a href="chapter-balance.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb10-7"><a href="chapter-balance.html#cb10-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-8"><a href="chapter-balance.html#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="chapter-balance.html#cb10-9" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-10"><a href="chapter-balance.html#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">14</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb10-11"><a href="chapter-balance.html#cb10-11" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-12"><a href="chapter-balance.html#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="chapter-balance.html#cb10-13" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-14"><a href="chapter-balance.html#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb10-15"><a href="chapter-balance.html#cb10-15" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-16"><a href="chapter-balance.html#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="chapter-balance.html#cb10-17" aria-hidden="true" tabindex="-1"></a>p5 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-18"><a href="chapter-balance.html#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb10-19"><a href="chapter-balance.html#cb10-19" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-20"><a href="chapter-balance.html#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="chapter-balance.html#cb10-21" aria-hidden="true" tabindex="-1"></a>p6 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-22"><a href="chapter-balance.html#cb10-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">5</span>, <span class="at">beta =</span> <span class="dv">11</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb10-23"><a href="chapter-balance.html#cb10-23" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-24"><a href="chapter-balance.html#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="chapter-balance.html#cb10-25" aria-hidden="true" tabindex="-1"></a>p7 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-26"><a href="chapter-balance.html#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">6</span>, <span class="at">n =</span> <span class="dv">13</span></span>
<span id="cb10-27"><a href="chapter-balance.html#cb10-27" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-28"><a href="chapter-balance.html#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="chapter-balance.html#cb10-29" aria-hidden="true" tabindex="-1"></a>p8 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-30"><a href="chapter-balance.html#cb10-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">29</span>, <span class="at">n =</span> <span class="dv">63</span></span>
<span id="cb10-31"><a href="chapter-balance.html#cb10-31" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-32"><a href="chapter-balance.html#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="chapter-balance.html#cb10-33" aria-hidden="true" tabindex="-1"></a>p9 <span class="ot">&lt;-</span> bayesrules<span class="sc">:::</span><span class="fu">plot_beta_binomial</span>(</span>
<span id="cb10-34"><a href="chapter-balance.html#cb10-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">46</span>, <span class="at">n =</span> <span class="dv">99</span></span>
<span id="cb10-35"><a href="chapter-balance.html#cb10-35" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span>
<span id="cb10-36"><a href="chapter-balance.html#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="chapter-balance.html#cb10-37" aria-hidden="true" tabindex="-1"></a>(p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3) <span class="sc">/</span> (p4 <span class="sc">+</span> p5 <span class="sc">+</span> p6) <span class="sc">/</span> (p7 <span class="sc">+</span> p8 <span class="sc">+</span> p9)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="027_balance_prior_post_files/figure-html/unnamed-chunk-10-1.png" alt="Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall'alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1)." width="95%" />
<p class="caption">
Figura 2.2: Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall’alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).
</p>
</div>
<p>La figura indica che, se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori. Invece, se il campione è piccolo, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori, in confronto ad una distribuzione a priori non informativa.</p>
<p>La conclusione che possiamo trarre dall’esempio di <span class="citation"><a href="#ref-Johnson2022bayesrules" role="doc-biblioref">Johnson, Ott, and Dogucu</a> (<a href="#ref-Johnson2022bayesrules" role="doc-biblioref">2022</a>)</span> è molto chiara: l’aggiornamento bayesiano è molto simile ai processi di ragionamento del senso comune. Quando le evidenze (i dati) sono deboli, non c’è ragione di cambiare idea (le nostre credenze “a posreriori” sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le evidenze sono irrefutabili, dobbiamo cambiare idea, ovvero modellare le nostre credenze su ciò che dicono i dati, quali che siano le nostre credenze pregresse. Non fare ciò significherebbe vivere in un mondo di fantasia (e avere scarsissime possibilità di adattarci al mondo empirico). L’aggiornamento bayesiano esprime in maniera quantitativa e precisa (ottimale) ciò che ci dicono le nostre intuizioni.</p>
<p>Incredibilmente, l’approccio frequentista nega questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato un un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un’opinione di un certo tipo sul fenomeno in esame, l’indicazione è di prendere seriamente il risultato del test <em>quali siano le evidenze precedenti</em> – le quali, possibilmente, mostrano che il risultato del test non ha senso. È sorprendente che un tale modo di pensare possa essere preso sul serio nella comunità scientifica, ma alcuni ricercatori continuano a seguire questo modo di (s)ragionare.</p>
</div>
<div id="collegare-le-intuizioni-alla-teoria" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Collegare le intuizioni alla teoria</h2>
<p>L’equilibrio che abbiamo osservato nell’esempio precedente nella distribuzione a posteriori tra la distribuzione a priori e i dati sembra essere molto intuitivo. Emerge inoltre come una necessità matematica. È infatti possibile riscrivere la <a href="#eq:ev-post-beta-bin-1">(<strong>??</strong>)</a> nel modo seguente</p>
<p><span class="math display" id="eq:ev-post-beta-bin">\[\begin{align}
\E_{\text{post}} &amp;[\Beta(\alpha + y, \beta + n - y)] = \frac{\alpha + y}{\alpha + \beta +n}\notag\\ 
&amp;= \frac{a+b}{a+b+n} \cdot \frac{a}{a+b} + \frac{n}{a+b+n} \cdot \frac{y}{n}.
\tag{2.1}
\end{align}\]</span></p>
<p>Questo indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori <span class="math inline">\(\left( \frac{\alpha}{\alpha+\beta}\right)\)</span> e la frequenze di successi osservata <span class="math inline">\(\left(\frac{y}{n}\right)\)</span>. I pesi sono <span class="math inline">\(\left( \frac{\alpha+\beta}{\alpha+\beta+n}\right)\)</span> e <span class="math inline">\(\left( \frac{n}{\alpha+\beta+n}\right)\)</span>; quindi, quando <span class="math inline">\(n\)</span> è grande rispetto ad <span class="math inline">\(\alpha + \beta\)</span>, conta molto quanto abbiamo osservato e poco l’aspettativa a priori; viceversa, quando <span class="math inline">\(n\)</span> è piccolo rispetto a <span class="math inline">\(\alpha + \beta\)</span>, le osservazioni contano poco rispetto all’aspettativa a priori.</p>
<p>Queste osservazioni ci possono far capire come scegliere i parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>: se vogliamo assumere totale ignoranza, la scelta coerente è <span class="math inline">\(\alpha = \beta = 1\)</span> (ogni valore di <span class="math inline">\(\theta\)</span> è ugualmente probabile); se invece abbiamo delle aspettative, possiamo scegliere <span class="math inline">\(\alpha\)</span> in modo che sia uguale al valore atteso a priori, mentre <span class="math inline">\(\alpha + \beta\)</span> esprime l’importanza che diamo all’informazione a priori: maggiore è il valore di <span class="math inline">\(\alpha + \beta\)</span>, più dati servono per allontanare la distribuzione a priori da quella a posteriori. Se <span class="math inline">\(n\)</span> è abbastanza grande, la distribuzione a posteriori è molto poco influenzata dalla distribuzione a priori, a meno di scelte estreme.</p>
<!-- Consideriamo una serie di lanci di una moneta con probabilità sconosciuta di successo (testa) $\theta$. Supponiamo di osservare $y$ successi in $n$ prove. Descrivendo questo esperimento casuale cob la distribuzione binomiale e  quantificando le nostre credenze a priori su $\theta$ con una distribuzione a priori Beta definiamo il seguente modello statistico: -->
<!-- $$  -->
<!-- \begin{aligned} -->
<!-- y & \sim \text{Bin}(n, \theta) \\  -->
<!-- \theta & \sim \text{Beta}(a, b) -->
<!-- \end{aligned} -->
<!-- $$ -->
<!-- Per studiare l'impatto della distribuzione a priori sulla funzione di verosimiglianza confronteremo due campioni di dati. Nel primo campione, $n = 24$ e $y = 7$; nel secondo campione, $y = 109$ e $n = 311$. La figura seguente descrive la funzione di verosimiglianza per i due campioni di dati. -->
<!-- ```{r, echo = F, fig.cap = "Verosimiglianza per due campioni di dati binomiali. Per il primo campione abbiamo $y = 7$ e $n = 24$; per il secondo campione $y = 109$ e $n = 311$."} -->
<!-- lh_tibble <-  -->
<!--   tibble( -->
<!--   theta = seq(0,1, length.out = 401), -->
<!--   `24/7` = dbinom(7, 24, theta), -->
<!--   `109/311` = dbinom(109, 311, theta) -->
<!-- )  -->
<!-- lh_tibble %>%  -->
<!--   pivot_longer( -->
<!--     cols = -1, -->
<!--     names_to = "example", -->
<!--     values_to = "likelihood" -->
<!--   ) %>%  -->
<!--   ggplot(aes(x = theta, y = likelihood, color = example)) + -->
<!--   geom_line(size = 1) + -->
<!--   facet_wrap(.~example, nrow = 2, scales = "free") + -->
<!--   guides(color = F) + -->
<!--     labs( -->
<!--     x = latex2exp::TeX("Probabilità di successo $\\theta$"), -->
<!--     y = latex2exp::TeX("Verosimiglianza $P(D | \\theta)$"), -->
<!--     title = latex2exp::TeX("Verosimiglianza Binomiale per due campioni di dati.") -->
<!--   ) + -->
<!--   bayesplot::theme_default() -->
<!-- ``` -->
<!-- La cosa più importante da notare è che, maggiore è la quantità di dati ($y = 109$ e $n = 311$), più piccolo diventa l'intervallo di valori dei parametri che rendono plausibili i dati che sono stati osservati. Intuitivamente, questo significa che più dati abbiamo, più piccolo sarà l'intervallo a posteriori dei valori plausibili dei parametri, a parità di tutto il resto. -->
<!-- Consideriamo ora le quattro distribuzioni a priori che abbiamo descrito in precedenza: -->
<!-- ```{r, echo = F, fig.cap = "Esempi di distribuzioni a priori per il parametro $\\theta_c$ nel Modello Binomiale."} -->
<!-- prior_tibble <- tibble( -->
<!--   theta = seq(0, 1, length.out = 401), -->
<!--   `non inf.` = dbeta(theta, 1, 1), -->
<!--   `debolm. inf.` = dbeta(theta, 5, 2), -->
<!--   `fortem. inf.` = dbeta(theta, 50, 20), -->
<!--   `puntuale` = dbeta(theta, 50000, 20000) -->
<!-- ) -->
<!-- prior_tibble %>%  -->
<!--   pivot_longer( -->
<!--     cols = -1, -->
<!--     names_to = "prior_type", -->
<!--     values_to = "prior" -->
<!--   ) %>% -->
<!--   mutate( -->
<!--     prior_type = factor(prior_type, levels = c('non inf.', 'debolm. inf.', 'fortem. inf.', 'puntuale')) -->
<!--   ) %>%  -->
<!--   ggplot(aes(x = theta, y = prior)) + -->
<!--   geom_line(size = 1) + -->
<!--   facet_wrap(~ prior_type, ncol = 2, scales = "free") + -->
<!--   labs( -->
<!--     x = latex2exp::TeX("Probabilità di successo $\\theta$"), -->
<!--     y = latex2exp::TeX("Probabilità a priori $P(\\theta)$"), -->
<!--     title = latex2exp::TeX("Diverse funzioni a priori per $\\theta$"), -->
<!--     subtitle = latex2exp::TeX("Modello Binomiale") -->
<!--   ) + -->
<!--   bayesplot::theme_default() -->
<!-- ``` -->
<!-- Combiniamo le quattro distribuzioni a priori con la verosimiglianza dei due campioni di dati. Così facendo notiamo che la distribuzione a posteriori è effettivamente un "miscuglio" della distribuzione a priori e della verosimiglianza. -->
<!-- ```{r, echo = F, fig.cap = "Distribuzioni a posteriori per il parametro $\\theta$ calcolate mediante diverse distribuzioni a priori per due campioni di dati."} -->
<!-- full_join(lh_tibble, prior_tibble, by = 'theta') %>%  -->
<!--     pivot_longer( -->
<!--     cols = 2:3, -->
<!--     names_to = "example", -->
<!--     values_to = "likelihood" -->
<!--   ) %>%  -->
<!--   pivot_longer( -->
<!--     cols = 2:5, -->
<!--     names_to = "prior_type", -->
<!--     values_to = "prior" -->
<!--   ) %>%  -->
<!--   mutate( -->
<!--     posterior = likelihood * prior -->
<!--   ) %>%   -->
<!--   filter( posterior != Inf) %>%  -->
<!--   group_by( example, prior_type) %>%  -->
<!--   mutate( -->
<!--     posterior = posterior/sum(posterior) -->
<!--   ) %>% -->
<!--   mutate( -->
<!--     prior_type = factor(prior_type, levels = c('non inf.', 'debolm. inf.', 'fortem. inf.', 'puntuale')) -->
<!--   ) %>% -->
<!--   ggplot(aes(x = theta, y = posterior, color = example)) + -->
<!--   geom_line(size = 1) + -->
<!--   guides(color = F) + -->
<!--   facet_grid(prior_type ~ example, scales = "free") + -->
<!--   theme(strip.text.y = element_text(size = 9, face = 'plain'))+ -->
<!--   labs( -->
<!--     x = latex2exp::TeX(" Parametro $\\theta$"), -->
<!--     y = latex2exp::TeX("Probabilità a posteriori $P(\\theta \\, | \\, D)$"), -->
<!--     title = latex2exp::TeX("Distribuzioni a posteriori per $\\theta$.") -->
<!--   ) + -->
<!--   bayesplot::theme_default() -->
<!-- ``` -->
<!-- Ciò che è importante notare è che, se il campione è grande, una distribuzioni a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori. Invece, se il campione è piccolo, anche una distribuzioni a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori, in confronto ad una distribuzione a priori non informativa. -->

</div>
</div>



<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Bechdel, Alison. 1986. <em>Dykes to Watch Out for</em>. Firebrand Books.
</div>
<div class="csl-entry">
Johnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. <em><span class="nocase">Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bechdel1986dykes" class="csl-entry">
Bechdel, Alison. 1986. <em>Dykes to Watch Out for</em>. Firebrand Books.
</div>
<div id="ref-Johnson2022bayesrules" class="csl-entry">
Johnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. <em><span class="nocase">Bayes Rules! An Introduction to Bayesian Modeling with R</span></em>. CRC Press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/027_balance_prior_post.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Science per psicologi.pdf", "Data Science per psicologi.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
